И каково это стоять на пороге технологической революции?
Это, должно быть, так волнующе, но вспомните один важный нюанс: когда вы стоите на временном графике функции, вы не видите, что находится справа от вас. На самом деле, стоять на пороге технологической революции — это вот так:
И по ощущениям, скорее всего, в этом нет ничего особенного...

Далекое будущее наступит скоро
Представьте, как вы отправляетесь с помощью машины времени в 1750 год. Время, где постоянно отключен свет, а для коммуникации на дальних расстояниях требуется либо кричать, либо стрелять в воздух из пушки, а весь транспорт заправляется сеном. Вот вы оказались там и первым же делом берете чувака и привозите его обратно в 2015, водите его по разным местам и наблюдаете за его реакцией. Невозможно даже представить, что он ощущает, впервые видя мчащиеся по шоссе блестящие капсулы, каково это — поговорить с людьми, которые находятся на другом конце света, посмотреть спортивный матч, который проводится в тысячах километрах от него, послушать музыкальное выступление, записанное полвека назад. Потом мы дадим ему поиграться с волшебным прямоугольником, с помощью которого он может запечатлеть движущиеся изображения, начертить карту с загадочной голубой точкой, которая указывает его местоположение, увидеться и поболтать с кем–то, кто находится на другом конце света и сотворить еще много других чудес. И все это до того, как вы начнете ему объяснять, что такое интернет, международная космическая станция, адронный коллайдер, ядерное оружие и общая теория относительности.

Все это не просто бы удивило и шокировало его, парень мог бы просто умереть.

Но вот любопытная штука – если бы потом этот же чувак отправился обратно в свой 1750 и из чувства зависти решил удивить кого–то так же как мы удивили его, и привез парня из 1500, то тот, конечно, удивился бы множеству вещей, но точно бы не умер. Для него такой опыт не стал бы шокирующим приключением, потому что хотя 1750 и 1500 были разными, они не были настолько разными, как 1750 и 2015. Парень из 1500, конечно, узнал бы поразительные вещи о пространстве и физике и был бы удивлен тому, как сильно Европу охватили ее империалистические причуды, а также ему пришлось бы значительно переосмыслить карту мира. Но повседневная жизнь — передвижение, коммуникации и т.п. явно бы его не убили.

Теперь, для того, чтобы парню из 1750 позабавиться с кем–то как мы повеселились с ним, ему придется отправиться в более раннюю эпоху, где–то в 12000 до нашей эры, до первой аграрной революции, которая заложила фундамент в развитии первых городов и цивилизаций. Если бы кто–то из эпохи охоты и собирательства увидел человеческую империю с возвышающимися соборами, кораблями пересекающими океаны, и все накопленные знания и открытия, то он бы, скорее всего, умер.

Что если после смерти он бы из зависти решил сделать то же самое с кем–то из прошлого, отправился бы в 24000 год до н.э. и взял оттуда человека, показал бы ему все, и тот бы сказал: «Ну норм, мне–то что?». Для того, чтобы парню из 12 века до н.э. провернуть подобное, ему потребовалось бы отправиться еще на 100 000 лет в прошлое и продемонстрировать там вербальную коммуникацию и огонь.

Таким образом, для того, чтобы умереть, испытывая шок от увиденного им прогресса, нужно отправиться в будущее на столько лет вперед, чтобы достичь единицы «смертельный уровень прогресса» (ЕСП). Во времена охоты и собирательства ЕСП равнялась 100000 лет, но после аграрной революции она стала равняться всего 12000 лет, а в результате постиндустриальной революции мир стал развиваться так быстро, что человеку из 1750 года нужно отправиться всего на пару столетий вперед, чтобы достигнуть ЕСП.

Такую модель, при которой человеческий прогресс движется быстрее с каждым годом, футуролог Рэймонд Курцвейл назвал Законом ускоряющейся отдачи. Все просто: так происходит, потому что более развитому обществу требуется меньше времени для прогресса, чем менее развитому. В 19 веке человечество знало больше и обладало более совершенными технологиями, чем в 15, люди 15 века не выдержали бы никакой конкуренции с людьми 19 века.

Это правило работает и в меньших масштабах. Фильм «Назад в Будущее» вышел в 1985 году, по сюжету «прошлое» разворачивалось в 1955 году. Оказавшись в 1955 году, герой Майкла Джея Фокса удивляется ценам на газировку, устаревшим телепрограммам и различиям в сленге. Да, для него это был другой мир, но если бы герою пришлось отправиться из сегодняшнего дня в 1985, то в картине было бы больше шуток, связанных с отличиями. Герой попал бы в мир без персональных компьютеров, интернета и мобильной связи. Сегодняшний Марти Макфлай, тинэйджер родившийся в 90х, ощущал бы себя не в своей тарелке в 1985 куда сильнее, чем киношный Марти Макфлай ощущает себя в 1955.

По этой самой причине я упомянул о Законе ускоряющейся отдачи. Средний темп развития между 1985 и 2015 намного выше, чем между 1955 и 1985. Первый промежуток охватывает стремительный рост в развитии, намного больше перемен произошло за последние 30 лет, чем за 30 лет до них.

Выходит, темп прогресса только ускоряется. Это значит, что наше будущее будет крутым, верно?

Курцвейл считает, что все достижения XX века уместились бы в 20 лет при темпе развития 2000 года, иными словами, к 2000 году темп развития был в 5 раз выше, чем средний темп развития в XX веке. Он также считает что прогресс, сопоставимый со всеми достижениями прошлого века, произошел в период между 2000 и 2014 и такой же совокупный результат повторится в следующий раз к 2021 году, всего через 7 лет. Спустя пару десятилетий достижения, сопоставимые с суммарным прогрессом XX века, будут повторяться несколько раз в год, а еще позже — вообще каждый месяц. В конечном итоге, согласно Закону ускоряющейся отдачи, XXI век превысит прогресс XX века в 1000 раз.

Если Курцвейл и все, кто с ним соглашаются, правы, то мы будем также шокированы 2030 годом, как наш паренек из 1750 был шокирован в 2015. То есть следующая ЕСП займет 20 лет, и мир в 2050 будет настолько отличен от нынешнего, что мы его просто не узнаем.

И это не научная фантастика. В это твердо верят многие ученые, которые поумнее нас будут. Если взглянуть на историю, именно такое предсказание будущего наиболее логично.

Конечно, вы мне не поверите, если я скажу, что через 35 лет мир будет неузнаваем. И вот по каким причинам:

1) Когда дело доходит до истории, мы мыслим прямыми линиями. Мы представляем себе прогресс следующих 30 лет, воспринимая прогресс предыдущих 30 лет как на некий общий ориентир. Размышляя о том, как изменится мир за это столетие, мы просто думаем обо всех достижениях XX века и прибавляем некий их эквивалент к 2000 году. Эту же ошибку совершил парень из 1750, когда привез первого чувака из прошлого в надежде потрясти его так же, как был потрясен он сам, когда побывал в будущем. Линейное мышление является для нас интуитивным, в то время как нам следует думать экспоненциально. Тот, кто оказался поумнее, сможет предсказать прогресс следующих 30 лет, принимая в расчет нынешний темп развития и отталкиваясь уже от него. Его предсказание оказалось бы более точным, но все равно весьма далеким от истины. Чтобы думать о будущем правильно, следует представлять себе более высокие скорости развития, чем те, при которых мы живем сейчас.
Линия движения новейшей истории часто приводит к путанице. Во–первых, даже крутая экспонента кажется прямой, если смотреть на очень короткий ее отрезок. Во–вторых, экспоненциальный рост не идеально гладок и однороден. По мнению Курцвейла, прогресс происходит в S–образных кривых:
S создается волной прогресса, которая наступает с образованием новой парадигмы. Изгиб проходит три фазы:

медленный рост (ранняя фаза экспоненциального роста);
быстрый рост (поздняя, взрывная фаза экспоненциального роста);
выравнивание (созревание новой парадигмы).
Часть кривой, в которой мы сейчас находимся, может запутать ваше восприятие того, как быстро все развивается. На промежуток времени между 1995 и 2007 пришелся взрыв развития интернета, появление в общественном сознании Microsoft, Google, Facebook, рождение социальных сетей и появление мобильных телефонов, а затем и смартфонов. Это все было второй фазой — скачком в росте. Период с 2008–го по 2015–й был менее новаторским, по крайней мере, в технологическом плане. Кто–то, думая о будущем сегодня, может рассматривать только последние несколько лет для оценки текущего уровня развития и не видит картину целиком. По сути, новая фаза скачка в росте может назревать снова прямо сейчас.

3) Наш собственный опыт превращает нас в упрямых стариков в вопросах о будущем. Наши представления о мире основываются на личном опыте. Этот опыт укоренил в голове представление о темпах роста недавнего прошлого как нечто абсолютное. Мы также ограничены нашим воображением, которое опирается на наш опыт при составлении прогнозов на будущее. Но часто то, что мы знаем, не предоставляет нам необходимый инструментарий, позволяющий верно мыслить о будущем (Курцвейл приводит в пример свой телефон, который в миллион раз меньше, миллион раз дешевле и в тысячи раз мощнее чем был его MIT компьютер 40 лет назад). Теперь попробуйте представить, с какими технологиями мы будем иметь дело в сравнительном будущем. Когда мы слышим прогнозы о будущем, которые идут вразрез с нашим, основанным на личном опыте представлением о том, как устроены вещи, мы инстинктивно думаем, что предсказания наивны. Если бы я вам в этом посте сказал, что вы, может быть, проживете 150 или 250 лет, а может и вообще не умрете, то ваш инстинкт скажет: «Это бред, одно я знаю наверняка из всей истории — все в итоге умирают». И это верно, ведь никто в прошлом не избежал смерти. Но и самолеты не летали, пока их не изобрели.

Так что пока вы думаете про себя «даааа нуууу» читая этот пост, вы, возможно, зря сомневаетесь. Суть в том, что пока мы хотим рассуждать по–настоящему логически и ожидаем, что историческая последовательность продолжится, мы должны прийти к заключению, что с последующими десятилетиями изменится намного больше всего, чем мы ожидаем. Логично также, что если самые развитые существа на планете продолжат делать все более высокие скачки в темпах своего развития, то в какой–то момент они коренным образом изменят жизнь и собственное восприятие себя как людей. Подобно тому, как эволюция делала большие скачки на пути к разумным существам, пока в конечном итоге не сделала такой большой скачок до хомо сапиенса, который полностью изменил жизнь на Земле. Если вы следите за тем, что происходит в мире науки и технологий сегодня, то вы начнете замечать множество вещей, указывающих на то, что привычный жизненный ход вещей, возможно, не выдержит следующий скачок.

Дорога к сверхинтеллекту
Что такое ИИ?

Если вы похожи на меня, то для вас искусственный разум — это выдумка из мира фантастики, и вы не до конца понимаете суть, когда слышите, как это обсуждают серьезные ученые.

Есть несколько причин, по которым людей смущает термин ИИ.

1) Мы связываем его с фильмами. Звездные войны, Терминатор, Космическая одиссея–2001 с вымышленными персонажами — роботами, которые заставляют нас думать об ИИ как о каком–то художественном вымысле.

2) ИИ — очень широкая тема. Он может быть представлен как в виде калькуляторов, так и в виде самоуправляемых автомобилей или даже чего–то, что в будущем сильно изменит нашу жизнь. ИИ относится ко всем этим вещам, что и приводит к путанице.

3) Мы пользуемся им в повседневной жизни, не осознавая того, что это искусственный интеллект. Джон Маккарти, который в ввел термин "искусственный интеллект" в 1956 году, жаловался: "Стоит ему действительно заработать, как все сразу перестают называть его ИИ." Из–за этого феномена термин звучит больше как нечто из разряда фантастики. В тоже время это звучит и как популярная концепция, которая так и не была реализована. Курцвейл говорил, что часто слышит, как люди говорят что идея ИИ изжила себя еще в 80–х, таких людей он сравнивает с теми, кто утверждает, что интернет умер с пузырем доткомов.

Итак, давайте внесем некую ясность. Первым делом перестаньте думать о роботах. Робот — это всего лишь оболочка ИИ, которая иногда подражает человеческому образу, но ИИ — это только компьютер внутри робота. ИИ – это мозг, а робот — это тело, если оно вообще есть. Например, помощник в iOS Siri (которая, кстати, скоро заговорит по–русски — прим. пер. ) — это ИИ, а женский голос — это персонификация ИИ, и при этом нет никакого робота.

Во–вторых, вы наверное слышали термин «сингулярность» или «технологическая сингулярность». Этот термин используется в математике, чтобы описать ситуацию, при которой обычные законы уже не действуют. В физике он используется для того, чтобы описать феномены вроде черной дыры или состояния, в котором пребывала Вселенная до Большого Взрыва. В 1993–м году Вернор Виндж использовал этот термин в своем знаменитом эссе, чтобы описать поворотный момент в истории, когда искусственный интеллект превысит человеческий, то есть жизнь изменится, и обычные правила будут неприменимы. Рэй Курцвейл потом еще немного запутал все, определив сингулярность как момент, когда ускоряющаяся отдача достигнет такого пика, при котором технологический прогресс начнет происходить в бесконечном темпе, после чего мы будем жить в совершенно ином мире. Как я заметил, сегодняшние исследователи ИИ не особо прибегают к этому термину, в любом случае он всех запутывает, так что я не буду приводить его здесь часто (хотя мы сосредоточим наше внимание на этой идее на протяжении всего текста).
Наконец, существует множество различных видов и форм ИИ, и, как мы уже решили — это в целом очень широкое понятие. Критические категории, которыми нам следует мыслить в вопросах ИИ, можно разделить на три основных уровня:
1) Слабый Искусственный Интеллект (ANI) — это такой ИИ, который специализируется в одной области. Есть ИИ, способный победить в чемпионате мира по шахматам, но это все, что он умеет. Скажи ему организовать информацию на жестком диске удобным способом, и он посмотрит на тебя пустым 1010101–взглядом.
2) Сильный Искусственный Интеллект (AGI), также известный как ИИ человеческого уровня, — это компьютер, способный решить любую умственную задачу, которую способен решить человек. Создать AGI намного сложнее, чем ANI, и нам это только предстоит сделать. Профессор Линда Готтфредсон описывает интеллект как «очень общую психическую способность, которая, помимо всего прочего, включает в себя способность рассуждать, планировать, решать проблемы, мыслить абстрактно, понимать сложные идеи, быстро учиться и учиться на опыте» AGI будет справляться со всем этим с такой же легкостью, как и вы.
3) Искусственный сверхинтеллект (ASI). Оксфордский философ и ведущий мыслитель в области ИИ Ник Бостром определяет ASI как «интеллект, который намного умнее лучших человеческих умов практически в любой сфере, в том числе научного творчества и социальных навыков». ASI, в свою очередь, варьируются от компьютеров, которые немного умнее человека, до тех, которые превышают возможности человеческого разума по всем направлениям в триллионы раз. ASI – причина по который ИИ — настолько острая тема, что в этом посте скоро появятся слова «аморальность» и «вымирание».
На сегодняшний день люди покорили ИИ только самого мелкого калибра, ANI, и теперь они повсюду. Революция Искусственного интеллекта – это путь от ANI через AGI к ASI. Дорога, которую мы переживем, а может и нет, но в любом случае она изменит абсолютно все.

Давайте внимательно посмотрим на то, каким видят этот путь ведущие мыслители в этой области и почему эта революция может произойти намного раньше, чем вы могли бы себе представить:


Сейчас весь мир работает на ANI

ANI, слабый ИИ – это такой искусственный интеллект, который равен или превышает человеческий интеллект или производительность только в одной конкретной сфере.

Вот несколько примеров:

Автомобили напичканы системами ANI – от компьютера, который просчитывает, когда включать антиблокировочную тормозную систему, до компьютеров, которые настраивают параметры системы впрыскивания топлива. Самоуправляемый автомобиль Google, который сейчас тестируется, будет содержать мощные ANI системы, которые позволят автомобилю воспринимать окружение и вовремя на него реагировать.

Ваш телефон — это небольшая фабрика ANI. Когда вы используете навигацию, определяете автора песни с помощью Shazam или проверяете погоду на завтра, болтаете с Siri или совершаете десятки других операций, вы используете ANI.

Спам–фильтр на вашей электронный почте – классический тип ANI, он начинает работу с предустановленной возможностью распознавать спам и затем учится и адаптирует свой интеллект под ваши конкретные предпочтения.

Знаете это жутковатую тему, когда вы ищете товар на Amazon, а затем этот товар вам рекомендуют на совсем другом сайте. Или когда Facebook понимает, кого стоит советовать для добавления в друзья. Это целая сеть ANI–систем, которые работают вместе, чтобы собрать необходимую информацию о вас и решить, что показывать в дальнейшем. Так же на сайтах работает функция «Люди, купившие этот товар, также купили это», чтобы повышать продажи и заставлять вас покупать больше.

Google–переводчик — еще один классический ANI, который очень хорошо справляется с одной задачей. Распознавание голоса — это уже другой ANI, но многие программы используют их вместе, что позволяет вам произнести целое предложение, и ваш телефон воспроизводит его уже на другом языке.

Когда ваш самолет приземляется, то не человек выбирает выход на посадку, и не человек определил стоимость вашего билета.

Лучшие игроки в шахматы, шашки, нарды и скрэббл теперь ANI–системы.

Поиск Google — это одна большая ANI со сложными методами отбора порядка страниц, которая решает, что вам показать по вашему запросу в первую очередь.

И все это только из сферы потребления, ANI–системы широко применяются в военной технике, производстве и финансах (алгоритмические высокочастотные ИИ–трейдеры продают больше половины пакетов акций на рынках США). Существуют экспертные системы, которые помогают врачам ставить верные диагнозы. Вспомните Ватсона от IBM, который содержал достаточное количество фактов и хорошо понимал речь Алекса Требека (телеведущего), что обыграл всех чемпионов Своей Игры (их аналога, нашего Петра Кулешова никто из ANI пока не обыгрывал).

Современные ANI–системы не такие уж страшные. В худшем случае глюченная или плохо спрограммированная ANI может вызвать локальную катастрофу, например, отключение энергосистем на атомной электростанции или спровоцировать обрушение рынка (вспомните Черный вторник 6 мая 2010, когда ANI неправильно отреагировала на неожиданную ситуацию, что привело к резкому обвалу биржевого рынка).

Пока ANI еще не представляют угрозу нашему существованию, нам следует понять всю эту большую и сложную систему относительно безобидных компьютеров, так как они предвещают надвигающийся ураган, который полностью изменит мир. Каждая отдельная инновация ANI закладывает новый кирпичик в дороге к ASI. Эрон Саенз сравнивает роль систем ANI в современном мире с «аминокислотам в первичном бульоне Земли», материалом, который в конечном итоге привел к возникновению живой клетки.
Дорога от слабого искусственного интеллекта к сильному



Почему она так трудна

Ничто не заставит вас ценить человеческий разум больше, чем осознание того, насколько сложно создать компьютер, который был бы так же умен, как и мы. Строительство небоскребов, запуск космических ракет, объяснение Большого Взрыва не так сложны, как изучение работы нашего мозга и создание чего–то столь же крутого. В настоящее время человеческий мозг является самым сложным объектом из известных нам во всей Вселенной.

Забавно, что настоящие трудности при создании сильного искусственного интеллекта (AGI) сильно отличаются от тех, что приходят к нам на ум в первую очередь. Разработать компьютер, который может умножить два десятизначных числа за секунду, невероятно легко. Куда сложнее разработать компьютер, который, взглянув на собаку, смог бы определить, что это не кошка. Разработать ИИ, способный выиграть у любого человека в шахматы? Да проще простого. Разработать ИИ, который будет способен прочитать предложение под картинкой в книжке для пятилетних детей, при этом не просто распознать слова, но и понять их смысл – куда сложнее. Google сейчас тратит миллиарды долларов, чтобы сделать нечто подобное. Тяжелые вещи вроде стратегий финансовых рынков, статистических вычислений и переводов на другие языки безумно легко даются компьютерам, тогда как простые вещи вроде зрения, движения и восприятия ужасно сложны для них. Как однажды сказал ученый Дональд Кнут: "ИИ преуспели почти во всем, что требует мышления, но не могут сделать большую часть того, что люди и животные делают не задумываясь".

К нам быстро приходит осознание того, что вещи, которые кажутся нам простыми, на самом деле невероятно сложны. Они кажутся нам легким только лишь, потому что эти навыки развила в нас эволюция за сотни миллионов лет. Когда ты тянешься рукой до предмета, то мускулы, сухожилия и кости в твоем плече локте и запястье в сочетании с глазами мгновенно выполняют длинную серию операций, чтобы позволить вашей руке сделать прямое движение сквозь три измерения. Это кажется легким только потому, что вы идеально отладили программное обеспечение в вашем мозгу для этой задачи. По такому же принципу можно сказать, что не вредоносные программы тупые, раз не могут разгадать эти дурацкие капчи, которые вам приходится вводить для регистрации на новом сайте, а наоборот, ваш мозг настолько потрясающий, что может легко с ними справиться.

С другой стороны, умножение больших чисел и игра в шахматы — это новые задачи для биологических существ, у нас просто не было достаточно времени, чтобы развить навыки для них, поэтому компьютер так легко нас в этом обходит. Подумайте, что бы вы сделали – программу, которая может умножать огромные числа или ту, которая понимала бы суть буквы “Й” достаточно хорошо, чтобы уметь распознать ее в миллионах вариаций шрифтов и почерков.
Вот один забавный пример – когда вы смотрите на это изображение, и вы, и компьютер легко понимаете, что перед вами прямоугольник в двух чередующихся оттенках:
Пока ничья. Но если вы уберете черный цвет и раскроете всё изображение...
… у вас не возникнет проблем с описанием полупрозрачных цилиндров и трехмерных углов, но компьютер здесь с треском провалится. Он бы описал то, что видит, как разнообразие различных двухмерных форм в нескольких оттенках, что там по сути и изображено. Ваш мозг проделывают кучу офигительной работы для того, чтобы толковать подразумеваемую глубину, смешение оттенков, пространственное освещение, которые изображены на картинке. На фотографии снизу компьютер видит двухмерный коллаж из черного и белого, в то время как вам сразу понятно, что на ней изображен черный камень:
И все, что мы только что упомянули, касается только принятия и обработки статичной информации. Чтобы быть разумным, как человек, компьютеру нужно считывать и понимать разницу между выражениями лиц, видеть различия между ощущениями довольства, облегчения, удовлетворения и радости, и понимать, почему «Храброе сердце» хороший фильм, а любой фильм Уве Болла — ужасный. Ну, почти любой, правда.

Жутковато.

Так как же нам с этим справиться?
Первый шаг на пути к созданию AGI (сильного ИИ) – увеличение вычислительных мощностей.
Для того, чтобы создание AGI стало возможным, безусловно, должна произойти одна вещь – увеличение мощности компьютерной техники. Чтобы система AGI была такой умной, как человеческий мозг, ей нужно сравняться с вычислительной мощностью мозга.

Один из способов выражения этой способности мозга – сумма вычислений в секунду (Герц) которые может совершить мозг. Чтобы вычислить это выражение, нужно определить максимальную частоту герц отдельно в каждой зоне головного мозга и затем сложить их.
Рэй Курцвейл нашел более быстрый способ вычислить это общее значение. Он предлагает измерять частоту герц отдельной зоны мозга и вес этого участка и умножить результат пропорционально весу всего мозга. Звучит немного сомнительно, но он проделывал это множество раз, измерял отдельные зоны мозга и общее количество всегда приходило приблизительно к одному и тому же результату — около 10 в 16й степени, 10 квадриллионов герц.

В настоящее время самый быстрый супер–компьютер в мире, китайский
Тяньхэ–2 , превысил этот результат с тактовой частотой около 34 квадриллионов Гц. Но эта железяка занимает площадь в 720 квадратных метров, потребляет 24 мегаватта электроэнергии, в то время как человеческий мозг всего 20 ватт, да и мозг стоит не 390 миллионов долларов. Согласитесь, он не особо подходит для широкого применения, да и для большинства областей промышленного производства.

Курцвейл предлагает рассматривать компьютеры из расчета уровень мощности, доступный за 1000 долларов. Как только этот уровень достигнет человеческого – 10 квадриллионов герц, тогда это будет значить, что AGI могут стать реальной частью нашей повседневности.
Закон Мура – исторически надежное правило, согласно которому максимальная вычислительная мощность в мире удваивается приблизительно каждые 2 года, то есть развитие компьютерных технологий, как и развитие человечества, растет в геометрической прогрессии. Разберемся, что имел ввиду Курцвейл, говоря про тысячу долларов с помощью этой таблицы:
Компьютеры, которые сейчас стоят 1000 долларов, по своей мощности равны мышиному мозгу и в тысячу раз меньше человеческого. Это не кажется чем–то серьезным, до тех пор пока вы не вспомните, что такая компьютерная мощность составляла триллионную от уровня мозга в 1985 году, миллиардную в 1995 и миллионную в 2005. То есть на данном этапе мы можем ожидать, что к 2025 году мы сможем позволить себе компьютер, конкурирующий с мозгом.

В плане железа и оборудования, энергия, необходимая для AGI, технически уже доступна сейчас в Китае и станет общедоступной через каких–то 10 лет. Но такая сырая вычислительная мощность сама по себе не делает компьютер умнее, так что следующий вопрос – как привнести человеческий интеллект во всю это мощность?
Второй шаг к AGI (сильному ИИ) – сделать его умным.

Достаточно противная часть. Правда заключается в том, что никто на самом деле не знает, как сделать его умным. Мы до сих пор гадаем, как заставить компьютер отличать собаку от кошки, распознавать странно написанную букву Й и понимать, что фильм так себе. Существует куча замысловатых стратегий, и в конечном итоге какая–то из них окажется действенной. Здесь я представлю 3 самых популярных подхода:
1) Плагиат мозга

Это как если бы ученые бесились от того, что у соседа по парте получается писать все контрольные на пять, а у них при всем усердии это и близко не получается. В конце концов они решают: «Ладно, плевать, мы просто спишем у него все ответы». И это не лишено смысла, мы мучаемся, чтобы создать совершенный компьютер, тогда как в голове у нас есть идеальный прототип для него.

Научный мир работает над обратным конструированием мозга, чтобы понять, как эволюции удалось сделать такую крутую вещь. По самым оптимистичным прогнозам, работу завершат к 2030 году. После того, как это произойдет, мы откроем все секреты нашего мозга и сможем, вдохновляясь этим, украсть все его инновации. Искусственная нейронная сеть является ярким примером компьютерной архитектуры, которая имитирует мозг. Она представляет собой сеть транзисторов — «нейронов», соединенных между собой, но изначально ей ничего не известно, подобно мозгу младенца. Способ, по которому она «учится», заключается в том, что сначала она пытается выполнить задание, например, распознать почерк, поначалу нейронные импульсы и догадки в расшифровке каждой отдельной буквы будут абсолютно случайными. Но когда ей скажут, что она сделала это верно, соединения транзисторов в последовательности, которая помогла найти правильное решение, станут крепче, если же наоборот, ответ будет неверным, они ослабнут. После долгого процесса таких случайных попыток и их оценки, сеть, сама по себе, формирует «умные» нервные пути и машина становится оптимизированной для выполнения этой задачи. Мозг учится подобным, но более сложным образом. С продолжением исследований мозга нам открываются все новые способы использования нейронной системы.

Более кардинальный плагиат включает в себя стратегию, которую можно было бы назвать «эмуляция всего мозга». Для это требуется разрезать реальный мозг на микрослои, сканировать каждый, использовать программное обеспечение, чтобы собрать точную реконструированную 3D–модель и затем реализовать ее в мощном компьютере. В таком случае у нас появился бы компьютер, способный на все то, на что способен и человеческий мозг. При самом удачном раскладе ученым удалось бы эмулировать реальный мозг с такой точностью, что личность и память человека, которому принадлежал мозг, остались бы нетронутыми при загрузке архитектуры мозга на компьютер. Условно говоря, мозг принадлежал Джиму, после смерти его сканировали и загрузили на компьютер, который проснулся бы Джимом. То есть Джим стал бы надежным ИИ человеческого уровня, и мы смогли бы теперь превратить его в супер ИИ, и не думаю, что тот был бы против.

Как далеки мы от достижения полной эмуляции мозга? Ну пока что нам удалось недавно эмулировать миллиметровый мозг червя, в котором всего 302 нейрона. В человеческом мозгу их порядка 100 миллиардов. Если от этого вам кажется, что проект обречен, то вспомните мощность экспоненциального прогресса. Сначала мы покорили мозг червя, потом последует муравьиный, за ним мозг мыши и, глядишь, все это покажется более правдоподобным.
2) Попробовать заставить эволюцию сделать то, что она уже сделала

Если мы решим, что контрольную соседа по парте списать очень тяжело, мы можем попробовать подготовиться к ней по его методу.
Вот что нам известно. Собрать компьютер по мощи равный нашему мозгу – возможно, эволюция нашего мозга является тому подтверждением. И если мозг окажется слишком сложным для того, чтобы его эмулировать, мы можем воссоздать вместо этого процесс его эволюции. Пытаться воссоздать мозг – это как построить самолет, скопировав взмах птичьего крыла – зачастую машины лучше сооружать с помощью ориентированного на них подхода, а не подражая биологии в точности.

Таким образом, чтобы построить AGI мы можем имитировать процесс эволюции. Существует метод под названием «генетические алгоритмы», который работает следующим образом: есть процесс производительности–и–оценки, который повторяется снова и снова (таким же образом, как биологические существа «производительны», то есть живы и «оцениваются» по тому, способны ли они к размножению или нет). Несколько компьютеров пытаются выполнять задачи, и самые успешные из них будут скрещиваться друг с другом путем внедрения половины ПО каждого из них в новый компьютер. Менее удачнее компьютеры будут уничтожаться. Спустя множество таких повторов, естественный отбор будет производить компьютеры всё лучше и лучше. Сложность будет заключаться в создании автоматизированного цикла размножения таким образом, чтобы процесс эволюции шел сам по себе.
Недостаток копирования эволюции заключается в том, что эволюция любит занимать миллиарды лет, а мы хотим с этим управится за несколько десятилетий.

Но у нас есть много преимуществ перед эволюцией. Во–первых, эволюция не предсказывает результаты и работает случайным образом, она производит больше бесполезных мутаций, чем полезных, но если мы будем ее контролировать, она станет глючить на пользу нам. Во–вторых, эволюция не стремится ни к чему, в том числе и к интеллекту, иногда окружающая среда может даже совершать отбор против развития разума (так как он требует много энергии). Мы, напротив, могли бы специально направить этот эволюционный процесс в сторону развития интеллекта. В–третьих, чтобы отбор был в пользу интеллекта, эволюции придется измениться в куче других аспектов – например, перенастроить способ, которым клетки вырабатывают энергию, ведь мы можем компенсировать эти нагрузки, используя электричество. Это все заняло бы намного меньше времени, чем естественный процесс эволюции, но все равно неясно, поможет ли нам это достигнуть требуемых улучшений и жизнеспособна ли эта стратегия.
3) Свалить всю эту проблему на сами компьютеры

Когда ученые окончательно впадут в отчаяние, они попытаются сделать так, чтобы контрольная сама себя написала. Тем не менее это один из самых обнадеживающих методов из всех. Идея заключается в том, что мы разработаем компьютер, который будет проводить исследования по ИИ и программировать изменения в собственной архитектуре, что позволит ему не только изучать, но и улучшить себя. То есть сами компьютеры стали бы учеными в области компьютеров для того, чтобы заниматься собственным развитием. Их основная задача — выяснить, как сделать себя умнее. Подробнее об этом позже.

Все это может произойти очень скоро.

Быстрое развитие железа и инновационное эксперименты с программным обеспечением происходят одновременно, и AGI может подкрасться к нам быстро и неожиданно по двум основным причинам:

1) При экспоненциальном росте скорость улитки может резко увеличится. Гифка наглядно это объясняет:
2) Когда дело доходит до программного обеспечения, прогресс может казаться медленным, но достаточно одного открытия для мгновенного скачка в развитии (когда мы считали вселенную геоцентрической, все вычисления давались нам с трудом, но как только мы поняли, что вселенная гелиоцентрическая, всё стало сразу намного проще). Или когда дело доходит до самосовершенствующегося компьютера, нам может показаться, что мы далеки от цели, но какое–то очередное автообновление может резко приблизить компьютер к уровню человеческого интеллекта.
Дорога от AGI (сильного ИИ) до ASI (сверхинтеллекта)

В какой–то момент мы соорудили AGI–компьютеры с человеческим уровнем общего интеллекта. Что дальше? Просто куча людей и компьютеров, живущих вместе в равенстве.

Как бы не так!

Дело в том, что AGI будет по–прежнему иметь значительные преимущества в сравнении с людьми:


Железо:

Скорость
Нейроны мозга не превышают 200 Гц, в то время как сегодняшние микропроцессоры (которые гораздо медленнее, чем те, что будут, когда появится сильный ИИ) работают с частотой 2 ГГц или в 10 миллионов раз быстрее наших нейронов. Скорость внутренней коммуникации человеческого мозга, достигающая 120 м/с, ужасно отстает от скорости компьютера, которая может достигнуть скорости света.

Размер и хранение
Мозг ограничен в размере формой наших черепов и не может стать намного больше, и даже если станет, скорость внутренней коммуникации не будет достаточной. Компьютеры могут увеличиваться до любого физического размера, что позволяет запихнуть в них гораздо больше железа, компьютеры с увеличенным объемом оперативной памяти (ОЗУ) и долгосрочной памяти (жесткий диск) обладают огромными возможностями и работают точнее, чем наша собственная память.

Надежность и долговечность
Не только память компьютера будет более точной, но и компьютерные транзисторы. В отличие от биологических нейронов, они меньше изнашиваются и могут быть легко отремонтированы или заменены.
Человеческий мозг также быстрее устает, в то время как компьютеры могут работать без остановок, при пиковой производительности 24 часа в сутки и 7 дней в неделю.

Программное обеспечение:

Возможность редактирования, возможность модернизации, и в целом вообще широчайшие возможности.
В отличие от человеческого мозга, компьютерная программа может обновляться и исправлять ошибки, с ней легко экспериментировать. Обновления ПО могут охватывать области, в которых человеческий мозг слаб. Программное обеспечение человеческого зрения сверхпередовое, но его способность к усовершенствованиям довольно низка. Компьютеры могут сравняться с человеком по уровню программного обеспечения, отвечающего за зрительную функцию, но оно также может стать более оптимизированным и улучшаться.

Коллективная способность.
Люди превосходят все другие биологические виды в коллективной работе. Начиная с развития языка и формирования крупных общин, с последующим изобретением письма и печати, а теперь и интернета или майнкрафта, гитхаба. Коллективный разум человечества является одной из основных причин, почему мы смогли так далеко оторваться от всех других видов. Но компьютеры обходят нас и в этом. Всемирная сеть ИИ может моментально синхронизировать все данные между отдельными компьютерами. Так что если один компьютер узнает что–то, эта информация мгновенно загружается на все остальные компьютеры. Группа компьютеров может взять на себя одну задачу и справиться с ней как единое целое, потому что в отличие от людей, они не станут спорить между собой, отстаивая мнения, у них нет мотиваций и личной заинтересованности, как у нас.

ИИ, который станет сильным (AGI) посредством запрограммированного самосовершенствования, не воспримет достижение уровня человеческого интеллекта, как некий поворотный момент. Только для нас это значимый показатель, следовательно, AGI не станет на нем останавливаться. А учитывая те преимущества, которыми будет обладать AGI с интеллектом, эквивалентным человеческому, достаточно очевидно, что на этом уровне он будет оставаться недолго и продолжит улучшаться, достигнув интеллекта, превышающего человеческий.

Когда это произойдет, мы, скорее всего, офигеем. Ведь с нашей точки зрения, А – несмотря на то что интеллект разных животных отличается, в любом случае он в разы менее развит, чем у нас, Б – самых умных людей мы считаем таковыми только потому, что сравниваем их с не очень умными.
Так что когда ИИ догонит уровень интеллекта животных, мы будем воспринимать его как что–то, что умнее животных. Когда он достигнет примитивнейших способностей человеческого интеллекта, мы, как выразился Ник Бостром, будем воспринимать его как «деревенского тупицу» и выглядеть наша реакция будет следующим образом – о, гляди, он как дурачок, до чего же это мило! Но проблема заключается в том, что разница в интеллектуальных способностях между деревенским тупицей и Эйнштейном лежит в очень небольшом диапазоне. И AGI быстро обгонит старину Альберта. И тогда нас осенит:
И что же дальше?

Интеллектуальный взрыв

Надеюсь, вы насладились временем, пока все было безобидно, потому что с этого момента вся эта история с ИИ начнет становиться ненормальной и пугающей. Я хочу напомнить, всё, что я буду говорить, по–прежнему имеет реальные научные подтверждения и является прогнозом на будущее, который составили самые высокоуважаемые мыслители и ученые современности. Просто держите это в уме, пока читаете.

Во всяком случае, как я уже сказал выше, большинство вариантов развития событий, по которым мы доберемся до AGI, подразумевают процесс самосовершенствования ИИ. И как только появится AGI, даже системы, которые разрабатывались с помощью методов, не включавших в себя самопрограммирование, станут достаточно умными, чтобы начать самостоятельно вносить в свою архитектору изменения, если они этого захотят.

И вот тут вся концепция начинает становиться еще интереснее. Давайте введем новое понятие: рекурсивное самосовершенствование. Работает оно следующим образом:

Система ИИ в какой–то момент, скажем, на уровне тупого деревенщины, программируется на самосовершенствование. Как только это происходит и она становится умнее, достигая уровня Эйнштейна, она продолжает развиваться, но уже обладая интеллектом Эйнштейна, на что будет требоваться меньше времени. По мере того, как скачки в развитии будут увеличиваться, AGI достигнет уровня ASI — это и называется Интеллектуальным Взрывом и служит окончательным примером действия Закона ускоряющейся отдачи.

Ведутся некоторые споры о том, как скоро ИИ достигнет общего уровня человеческого интеллекта. По опросам сотен ученых, это, вероятно, произойдет к 2040, что всего через 25 лет, и это не так уж и нескоро.

Но может произойти и следующее:
Слабому ИИ потребуется несколько десятилетий, чтобы стать AGI с низким уровнем интеллекта, но в конечном итоге это все равно произойдет. Компьютер будет способен понимать окружающий мир на уровне четырехлетнего ребенка, но уже через час он будет понимать сложнейшую теорию физики, которая объединяет теорию относительности с теорией квантовой механики, что не удавалось сделать ни одному человеку. Через еще полтора часа AGI достигает уровня ASI и будет превышать интеллект любого человека в 170000 раз или 270000, или какая разница вообще.

Сверхинтеллект такой величины мы даже отдаленно понять не сможем. Все равно, что шмель попытается разобраться в Кейнсианской экономике. В нашем мире уровень IQ составляет в среднем 130 баллов для умного человека и 85 для глупого, мы даже не способны представить уровень IQ в 12952.

Точно известно, что абсолютное доминирование людей на Земле предполагает четкое правило – с разумом приходит сила. Это означает, что ASI станет самым мощным созданием, когда–либо существовавшим на Земле, и это может произойти через несколько десятилетий.

Если наши скудные мозги были способны придумать Wi–Fi, то чему–то, что в 100 или 1000 или 1000000000 раз умнее, чем мы, не составит труда контролировать расположение каждого отдельного атома во вселенной.
Все, что мы привыкли воспринимать как некую магию, любая сила, считавшаяся нами чем–то божественным, станет для ASI простой, как выключение света. Создание технологии обратного старения человека, лечение болезней и голода, перепрограммирование погоды для защиты будущей жизни на Земле — все это станет возможным. Но также возможным будет и моментальное прекращение существования всех форм жизни на Земле.

ASI станет всемогущий Богом на Земле, и самым важным вопросом для нас останется тогда этот:


Будет ли этот Бог добрым?

«Перед нами стоит чрезвычайно сложная задача. и неизвестно, сколько времени потребуется на ее решение, вполне возможно, от этого зависит судьба всего человечества» — Ник Бостром
Теперь вы, уставившись в экраны мониторов, наверное, гадаете, какие чувства вам следует испытывать, пока вы пытаетесь переварить эту информацию. Тем временем, до того, как окунуться во все это с головой, давайте вспомним, что значит для машины обладание сверхинтеллектом.

Существует ключевое различие между быстрым сверхинтеллектом и качественным сверхинтеллектом. Часто, когда мы пытаемся представить суперумный компьютер, мы первым делом думаем, что он так же умен, как и человек, только способен думать намного быстрее (вспомните х/ф «Она», скорость является основной чертой, отличающей супер ОС от человека), то есть, ему потребуется минут пять, чтобы решить задачу, на которую у человека уйдет лет десять.

Звучит впечатляюще, и ASI действительно будет мыслить в разы быстрее любого человека, но настоящее отличие будет заключаться в качестве этого мышления, а не в его скорости, что принципиально все меняет. Разница в умственных способностях между человеком и шимпанзе заключается не в скорости мышления, а в том, что человеческий мозг содержит большее количество сложных когнитивных модулей, которые позволяют нам строить сложные лингвистические обозначения, долгосрочные планы или отвлеченные рассуждения, тогда как мозг шимпанзе на это просто не способен. Ускорение работы мозга шимпанзе в тысячу раз не принесет такого результата даже через десятилетие. Шимпанзе по–прежнему не будет способен собрать замысловатую модель, используя набор специальных инструментов, тогда как человек справится с этим за пару часов. Существует огромное количество когнитивных функций, которые никогда не станут доступны шимпанзе, вне зависимости от того, сколько времени у него уйдет на попытки.

Проблема не в том, что шимпанзе не может делать то же, что под силу нам, а в том, что шимпанзе даже не способен понять, что такие возможности существуют. Шимпанзе может приблизительно понимать, что такое человек и что такое небоскреб, но он никогда не поймет, что люди построили небоскребы. Для шимпанзе все большое является частью природы и точка, сама возможность построить небоскреб лежит за гранью его понимания. Все это является результатом небольшого различия в качестве разума.

В масштабе интеллектуального диапазона, о котором мы говорим сейчас, или даже такого диапазона между биологическими существами, разница между интеллектом шимпанзе и интеллектом человека ничтожно мала. Специально для вас я решил выстроить в ряд биологические существа по уровню их когнитивных возможностей, используя изображение лестницы (А — Расположение этих существ на лестнице не основано ни на каких научных данных и просто призвано донести общую суть, Б – я очень горжусь этими рисунками):
Теперь для того, чтобы понять, насколько важным будет появление сверхразумных компьютеров, представьте, что один из них находится на той темно–зеленой ступени, что на две выше, чем человек. И это будет всего лишь слегка сверхразумная машина, но разница в когнитивных способностях между ней и нами будет такой же, как и разница между человеком и шимпанзе. Как и шимпанзе, неспособный понять небоскребы, мы никогда не сможем понять что–то, что под силу компьютеру на темно–зеленой ступени, даже если бы он постарался нам это объяснить, не говоря уже о том, чтобы сделать это самим. И он всего только на две ступни выше нас. Машина на предпоследней ступени сверху будет для нас, как мы для муравьев, она может годами пытаться дать нам простейшее представление о том, что ей известно, и все будет без толку.

Но сверхинтеллект, о котором мы говорим, сейчас расположен далеко за пределами этой лестницы. При интеллектуальном взрыве, чем умнее машина становится, тем быстрее она способна совершенствовать свой интеллект. Машине могут потребоваться годы, чтобы сделать шаг и стать на ступень выше шимпанзе, но потом, возможно, ей понадобится всего несколько часов, чтобы перепрыгнуть на темно–зеленую ступень, после чего дальнейшие скачки будут занимать считанные секунды. Поэтому важно понимать, что пройдет совсем немного времени от момента, когда мы услышим новости о создании первого компьютера, сравнимого по интеллекту с человеком, до момента, когда мы начнем сосуществовать на Земле с компьютерами, которые будут на миллионы ступеней выше нас.
Раз мы уже договорились, что нет смысла даже пытаться понять машину, которая на две ступени выше нас, давайте конкретно раз и навсегда договоримся, что нет ни малейшего шанса предугадать, что сделает с нами ASI и какими для нас окажутся последствия. Любой, кто попытается сделать вид, что может это предсказать, явно ничего не смыслит в сверхинтеллекте.

Эволюция совершенствовала биологический мозг медленно и постепенно в течение сотен миллионов лет, и в этом плане создание человеком сверхинтеллекта будет большим плевком в сторону эволюции. Хотя, возможно, это и есть часть эволюции – может, она устроена таким образом, что человеческий разум развивается до тех пор, пока он не становится способен создать искусственный сверхразум, что служит неким детонатором. который вызовет взрыв, определяющий будущее для всех живых организмов:
По причинам, которые мы обсудим позже, большая часть научного сообщества считает, что вопрос не в том, наступим ли мы на эту мину, а когда. Такая информация немного сносит крышу.

И куда это нас приведет?

Никто в этом мире, и уж точно не я, не сможет ответить вам на этот вопрос. Но Оксфордский профессор философии и лидирующий исследователь в области искусственного интеллекта, Ник Бостром считает, что мы можем свести все варианты событий в две широкие категории.

Во–первых, взглянув на историю, мы видим, что жизнь устроена следующим образом: новый вид появляется, существует какое–то время и потом неизбежно теряет равновесие и сваливается с бревна жизни, оказываясь в зоне вымирания:
«Все виды в конечном счете вымирают» — было почти таким же надежным правилом, как и «все люди умирают». Пока что 99.9 % живых существ не удержали свое равновесие и сорвались с бревна. Отчетливо ясным кажется, что находясь на грани вымирания и из последних сил цепляясь за это бревно, вид может быть легко сброшен любым катаклизмом или появлением нового вида. Ник Бостром называет вымирание аттрактором — состоянием, в которое попадают все существа и никогда из него не возвращаются обратно.

Хотя большинство ученых, с работами которых я сталкивался, считают, что появление ASI обречет человечество на вымирание, многие все же верят, что при грамотном использовании ASI может привести отдельных людей или весь вид ко второму состоянию аттрактора – бессмертию вида.

Бостром убежден, что бессмертие вида, как и его вымирание, представляет собой состояние аттрактора. Как только мы достигнем его, мы навсегда победим смерть. Таким образом, несмотря на то, что все виды до сих пор падали в сторону зоны вымирания, Бостром считает, что у бревна есть два края и никто на Земле еще не был достаточно умен, чтобы понять, как свалиться в другую сторону.
Если Бостром и те, кто с ним согласны, действительно правы, а судя по всему тому, что я успел прочесть, у них есть все шансы оказаться таковыми, то нам предстоит принять два шокирующих факта:

1) Появление ASI впервые откроет для видов возможность свалиться с бревна жизни в сторону бессмертия, а не вымирания.

2) Появление ASI окажет такое огромное влияние на жизнь человечества, что, скорее всего, столкнет человеческий вид с бревна жизни в ту или иную сторону.

Очень вероятно, что когда процесс эволюции подведет нас к этой бомбе, взрыв навсегда положит конец человеческой связи с бревном баланса и создаст новый мир с людьми в нем или без них.
Кажется, единственный вопрос, которым нам следует задаваться сейчас, — в какую сторону мы свалимся с бревна баланса, когда наступим на эту бомбу и, собственно, когда это все произойдет?

Никто точно не знает, но многие ученые потратили кучу своих сил и времени, размышляя над этим вопросом. Оставшуюся часть поста мы потратим на исследование результатов их деятельности.
Начнем с первой половины вопроса: когда мы наступим на бомбу?
Как долго придется ждать, пока машины достигнут уровня сверхинтеллекта?

Неудивительно, что оценки приводятся совершенно разные, и среди ученых ведутся жаркие споры по этому поводу. Многие, как профессор Вернор Виндж, ученый Бен Гёрцель, соучредитель компании Сан Майкросистемс Билл Джой и более известный изобретатель и футуролог Рей Курцвейл согласились с экспертом машинного обучения Джереми Говардом, когда тот представил следующий график на Ted Talk:
Все эти люди убеждены, что это произойдет скоро – экспоненциальный рост в действии, машины становятся все умнее, и, хотя пока этот процесс кажется медленным, мы и опомниться не успеем, как они уже нас обгонят через несколько десятилетий.

Другие вроде соучредителя Microsoft Пола Аллена, психолога исследований Гари Маркуса, ученого Нью–Йоркского университета Эрнеста Дэвиса и технопредпринимателя Митча Капора считают, что ученые, подобные Курцвейлу, значительно недооценивают масштабы задач, и мы не так уж и близки к взрыву.

Лагерь Курцвейла, напротив, считает, если что–то и недооценивается, так это экспоненциальный рост, и сравнивает сомневающихся с теми, кто, глядя на развитие интернета в 1985 году, говорили, что глобальная сеть не окажет большого влияния на мир в ближайшем будущем.

Третий лагерь во главе с Ником Бостромом убежден, что ни у первых, ни у вторых нет достаточных оснований быть уверенными в своих прогнозах и считает, что: А — это может произойти в ближайшем будущем; Б — это может затянуться, и на значительно больший срок.

Конечно же, есть и такие, в их числе философ Хьюберт Дрейфус, которые считают, что все три лагеря наивны и глубоко заблуждаются: никакой бомбы нет и быть не может, т.к. создание ASI невозможно.

Что мы получим сложив вместе все эти точки зрения вместе?
В 2013 году в ходе ряда конференций Ник Бостром провел опрос, в котором участвовали сотни экспертов в сфере искусственного интеллекта. Всем им нужно было дать ответ на один вопрос: “Когда, по вашему мнению, будет создан искусственный интеллект человеческого уровня?” Им нужно было дать оптимистичное предположение (есть шанс в 10%), правдоподобный прогноз (50% уверенности) или безопасную догадку (год, в котором уже с 90% вероятностью будет создан AGI). Вот результаты собранных и обработанных данных:

Средний оптимистичный год (вероятность 10%): 2022
Средний реалистичный год (вероятность 50%): 2040
Средний пессимистичный год (вероятность 90%): 2075

В среднем опрошенные считают, что, скорее всего, через 25 лет AGI станет реальностью. Если вы подросток, то, согласно пессимистическому прогнозу, AGI точно появятся уже при вашей жизни.
Отдельное исследование недавно провел писатель Джеймс Баррат на ежегодной конференции Бена Гёрцеля, посвященной AGI. В опросе Баррат предлагал участникам выбрать из списка год, когда будет создан AGI. Варианты предлагались следующие: 2030, 2050, 2100, позже и никогда. Вот результаты:

К 2030: 42 % опрошенных
К 2050: 25 %
К 2100: 20 %
После 2100: 10 %
Никогда: 2 %

Эти результаты достаточно схожи с теми, что получил Бостром. В опросе Баррата больше 2/3 участников заявили, что AGI появится к 2050 году и чуть меньше половины считают, что это произойдет в течение следующих 15 лет. Поражает также, что всего 2 процента вообще не верят в достижение AGI.

Но помните, что не AGI должен вызвать взрыв, а последующий за ним ASI. Кода же, по мнению ученых, появится ASI?
Бостром также спросил у экспертов, когда, по их мнению, мы достигнем сверхинтеллекта, предложив следующие варианты ответа: А) в течение 2 лет (т.е. интеллектуальный взрыв последует почти незамедлительно) после изобретения AGI; Б) в течение 30 лет. Теперь смотрим результат:
По результатам среднего прогноза, возможность резкого скачка маловероятна — всего 10% опрошенных, а более длительных переход возможен с вероятностью в 75%.

Эти данные не дают нам среднего процента вероятности (50%), но с целью приблизительного прогноза, основанного на двух вышеперечисленных ответах, предположим, что они сказали “20 лет”. Согласно среднему прогнозу экспертов в области ИИ, по самому правдоподобному прогнозу мы достигнем сверхинтеллекта приблизительно к 2060 году (2040 год — появление AGI, плюс наш прогноз 20–летнего перехода от AGI к ASI)
Конечно, все вышеперечисленные статистические данные спекулятивные и представляют собой только среднее мнение среди экспертов в области ИИ, но они показывают, что большинство людей, которые лучше всех осведомлены в этой теме, согласились бы, что 2060 – достаточно разумное предположение для года, когда появится сверхинтеллект, который изменит мир. От этого момента нас отделяет всего 45 лет.

Хорошо, теперь насчет второй части вопроса –
с какого края бревна мы свалимся, когда произойдет взрыв?

Сверхинтеллект будет обладать огромной мощью, и критическим для нас станет следующий вопрос:

Кто будет контролировать эту мощь и какая у него будет мотивация?


В зависимости от ответа на него, мы решим, должен ли ASI вызывать у нас восхищение или страх.

Конечно же, научное сообщество и здесь существенно расходится в мнениях и ведет жаркие споры. В опросе Бострома участникам предлагалось оценить вероятность возможных последствий влияния AGI на человечество: 52% считают, что последствия будут хорошими или даже очень хорошими; 31% считают, что последствия будут плохими или очень плохими. Только 17% посчитали, что последствия будут нейтральными. Иными словами, люди, которые лучше всего осведомлены в этой теме, уверены, что это все это очень серьезно. Следует заметить, что речь здесь шла только об AGI, если бы вопрос был об ASI, процент с нейтральной оценкой, вероятнее всего, был бы намного ниже.

Пока мы еще полностью не углубились во всю эту риторику хороших и плохих последствий, давайте пока объединим обе части вопроса «когда это случится?» и «будет ли это чем–то плохим или хорошим» в один график, который включает в себя мнения большинства соответствующих экспертов:
Мы поговорим о главенствующем лагере через минуту, а пока скажите, определились ли вы со своей позицией? На самом деле, я знаю, что вы скажете, потому что я считал так же, пока не углубился в исследование этого вопроса. Некоторые причины, по которым люди не особо задумываются над этой темой:

Как мы уже говорили фильмы существенно запутали нас, показывая нереалистичные сценарии развития ИИ, заставляя нас думать, что ИИ не является чем–то, что стоит воспринимать всерьез. Джеймс Баррат сравнивает подобную реакцию с тем, как если бы центры по контролю и профилактике заболеваний сделали бы серьезное предупреждение о надвигающейся опасности наступления эпидемии зомби.

Это называется когнитивными предрассудками, нам тяжело поверить в реальность чего–то, пока мы не увидим доказательства этому. Я уверен, что ученые в 1988 постоянно обсуждали насколько серьезным будет развитие интернета, но люди не задумывались о том, как он изменит их жизнь, пока этого не произошло. Отчасти так было из–за того, что компьютеры в 1988 году не были столь функциональны, и глядя на них, люди не верили, что те скоро изменят их жизни. Их воображение было ограничено личным опытом и не позволяло отчетливо представить себе, чем могут стать компьютеры. То же самое происходит сейчас и с ИИ. Мы слышим, что это все очень серьезно, но наш опыт, которому известны только относительно слабые ИИ, усложняет для нас возможность поверить в коренные перемены, которые привнесет сверхинтеллект. С такими предрассудками и борются эксперты, пытаясь отвлечь наше внимания от ежедневного шума нашего эго.

Даже если бы мы и поверили – сколько раз за день вы задумываетесь о том, что проведете большую часть вечности в небытии? Не так много, верно? Хотя этот факт значимее любого из ваших повседневных занятий. Наш мозг концентрируется в основном на более мелких обыденных задачах, независимо от того, насколько безумной является долгосрочная ситуация, в которой мы находимся. Просто мы так устроены.

Одна из целей этого поста — переманить вас из лагеря «Я люблю думать о других вещах» в один из экспертных лагерей, даже если вы просто стоите в абсолютной неуверенности на пересечении двух пунктирных линий в нижней диаграмме.

В ходе этого исследования я наткнулся на десятки различных мнений по данному вопросу, но быстро заметил, что их все можно объединить в один основной лагерь и, в частности около ¾ экспертов попали в два подлагеря внутри основного:
Сейчас мы тщательно по всем ним пройдемся, на давайте начнем с самого интересного.

Почему будущее может стать для нас сладким сном?


По мере того, как я изучал мир ИИ, я обнаружил, что много людей находятся в Уверенном уголке на нашем графике.

Все они там просто гудят от волнения. Их взор устремлен к хорошей стороне бревна, и они убеждены, что именно туда мы все и направляемся. Для них будущее — это все, на что они так сильно надеялись и все это подоспеет вовремя и как нельзя кстати.

Что отличает их от других мыслителей, мы обсудим чуть позже, но это не их жажда оказаться на другом краю бревна, а их уверенность, что мы непременно приземлимся с противоположной стороны.

Откуда берется такая уверенность – предмет отдельного спора. Критики считают, что те просто ослеплены своей взволнованностью по поводу будущего и не видят возможных негативных последствий. Сторонники же говорят, что предрекать судный день наивно, ведь технологии всегда в большей степени помогали нам, чем вредили.

Мы охватим мнения обеих сторон, и по прочтении вы сможете определиться с собственной точкой зрения, но на данном этапе отложите своей скептицизм. Давайте лучше посмотрим на хорошую сторону бревна баланса и постараемся принять факт, что то, о чем вы сейчас читаете, вполне может стать реальностью. Если бы вы рассказали охотнику–собирателю о нашем мире домашнего комфорта, технологий и бесконечного изобилия, ему бы это могло показаться выдумкой, так что давайте будем честны и признаем, что столь же непостижимая трансформация может произойти и в нашем будущем.

Ник Бостром описывает три возможных типа функционирования ИИ:

Оракул – с точностью отвечает почти на любой вопрос, включая и сложные для человека, например, как создать более эффективный автомобильный двигатель? Google представляет собой примитивный вид оракула.

Джинн – исполняет любую команду высокой сложности. Например: используй молекулярный ассемблер для создания боле эффективного автомобильного двигателя. После чего ждет новую команду.


Суверен — сам решает, как ему лучше действовать и какие решения принимать, функционирует независимо с целью выполнить широко поставленную задачу. Например – изобрети более быстрое, экономичное и безопасное средство для частного передвижения людей.

Такие вопросы и задачи кажутся нам очень сложными. Их выполнение для сверхинтеллекта будет чем то вроде того, как если бы нас попросили исправить ситуацию, в которой карандаш упал со стола, и мы бы с легкостью выполнили задачу, просто подняв и положив карандаш обратно на стол.

Элиэзер Юдковский, житель Тревожного проспекта нашей таблицы, хорошо подметил:

“Не существует сложных проблем, есть только проблемы, которые сложны для определенного уровня интеллекта. Поднимитесь малость вверх (по уровню интеллекта), и решение некоторых «невозможных» проблем резко станет «очевидным». Подниметесь на уровень значительно выше и все станет «очевидным»”

В Уверенном уголке прописалось множество непоседливых ученых, изобретателей и предпринимателей, но для экскурсии по самой светлой стороне горизонта ИИ мы бы предпочли, чтобы нашим гидом был только один человек.

Персона Рэя Курцвейла достаточно противоречива. Я натыкался на разные отзывы, одни ему поклоняются и боготворят его идеи, другие же с презрением закатывают глаза, услышав его имя. Некоторые находятся посередине, как писатель Дуглас Хофштадтер, который отозвался об идеях изложенных в книгах Курцвейла следующим красноречивым образом: «Это все равно что смешать хорошую еду с собачьими экскрементами, так что в итоге невозможно решить, хорошая она или нет».

Неважно, нравятся вам его идеи или нет, невозможно не согласиться с тем что личность Курцвейла, как минимум, впечатляет. Уже подростком он начал свою деятельность, а в последующие десятилетия сделал несколько прорывных изобретений, включая первый планшетный сканер, первый сканер–преобразователь текста в речь (позволяя слепым людям читать обычные книги), хорошо известный синтезатор Курцвейла (первое настоящее электрическое пианино) и первый коммерчески доступный распознаватель речи с большим словарным запасом.

Курцвейл написал 5 бестселлеров. Он хорошо известен за свои смелые прогнозы, значительная часть которых оказалось верна, например в 80–х, когда интернет еще был чем–то загадочным, он предсказал, что в 2000–х интернет станет глобальным феноменом. Wall Street Journal прозвал его «неугомонным гением», журнал Forbes — «потрясающей думающей машиной», журнал Inc – «законным наследником Эдисона», а Билл Гейтс отозвался о нем как о «лучшем провидце будущего ИИ из всех, кого он знает».

В 2012 соучредитель Google Ларри Пейдж пригласил Курцвейла занять должность технического директора. (прим.: в интервью Guardian Курцвейл объяснил свою миссию в Google: «моя основная задача заключается в том, чтобы заставить Google понимать естественный язык, и я решаю, каким образом этого достигнуть. Окончательная цель моего проекта состоит в том, чтобы поиск понимал настоящее значение слов. Компьютеры не способны воспринять идею этой статьи, и мы хотим, чтобы они на самом деле научились читать. Мы хотим, чтобы компьютеры прочитали все в интернете, каждую страницу каждой книги, для того чтобы вступить с нами в полноценный диалог и дать ответы на наши вопросы». И Google, и Курцвейл считают, что все дело в языке).

В 2011 году Курцвей стал соучредителем Университета Singularity, который находится под опекой NASA и частично финансируется Google. Такое количество достижений – точно неплохой результат для одной жизни.

Вся эта биографическая справка приводится мною неспроста. Когда Курцвейл формулирует свое видение будущего, он звучит как помешанный, но важно понимать, что это не так – он поразительно умен и эрудирован в этих вопросах. Короче, вам может показаться, что он не прав, но помните, что он далеко не дурак. Осознание того, что это вполне себе приличный мужик, делает меня счастливым, так как я очень хочу, чтобы его прогнозы оказались верны. И вы, наверное, тоже.

Несложно догадаться, почему у него так много страстных последователей, известных как Сингуляританцы. Большинство его прогнозов широко разделяют ученые из Уверенного уголка, среди которых Питер Диамандис и Бен Гёрцель. Вот что, по их мнению, должно произойти:

Хронология


Курцвейл считает, что к 2029 году мы создадим искусственный интеллект, равный человеческому, а к 2045 у нас будет не только сверхинтеллект, но и полномасштабный новый мир, и этот момент он называет сингулярностью. Такой расчет до сих пор продолжает казаться многим безумно преувеличенным (прим. технопредприниматель Мич Капор даже поспорил с Курцвейлом на 200 000 долларов, что мы не достигнем AGI к 2030 году), но с учетом того, как за последние 15 лет развились слабые системы ИИ, все больше экспертов соглашается с Курцвейлом. Его прогноз по–прежнему более амбициозный, чем прогноз среднего участника Бостромского опроса (AGI — 2040; ASI — 2060) но не так уж и сильно.

По мнению Курцвейла, к сингулярности в 2045 нас приведут три одновременные революции в биотехнологиях, нанотехнологиях и, в наибольшей степени, в области разработок ИИ.

Прежде чем мы двинемся далее, следует сказать, что нанотехнологии являются неотъемлемой частью всех разработок, касающихся ИИ, так что давайте сделаем небольшое отступление и обсудим нанотехнологии.

Отступление о нанотехнологиях


Нанотехнологии — термин для обозначения технологий, которые имеют дело с манипуляцией материи, чей размер варьируется между 1 и 100 нанометрами. Нанометр равен одной миллиардной части метра или миллионной части миллиметра. Под этот диапазон от 1 до 100нм попадают вирусы (длинною в 100нм), ДНК (10нм в ширину), а также молекулы гемоглобина (5нм), глюкозы (1нм) и многое другое. Если нанотехнологии станут подвластны нам, следующим шагом станет возможность манипулировать атомами, которые всего на один порядок величины меньше (~ 0,1нм). Следующий шаг будет намного сложнее — манипуляции субатомными частицами в ядре атома, протонами и нейтронами. Они намного меньше – диаметр протона составляет около 1,7 фемтометра, один фемтометр является одной миллионной частью нанометра.

Для того, чтобы понять, в чем состоит сложность манипуляции в подобных масштабах, давайте перенесем это в масштабы покрупнее. Международная Космическая станция находится на расстоянии в 431 км над поверхностью Земли. Если бы люди были великанами и доставали до МКС головой, то они были бы в 250 000 раз больше. Если увеличить что–то от 1 до 100 нанометров в 250 000 раз, вы получите 2,5 сантиметра. Продолжая сравнение, представьте, что такой гигант, цепляющий головой МКС, стал бы пытаться строить сложные объекты, используя инструменты размером с песчинку или глазное яблоко.

Для достижения следующего этапа, манипуляции атомами, великану бы пришлось аккуратно работать с объектами, которые по своему размеру составляют 1/40 миллиметра, настолько мелкими, что даже обычным людям нужен микроскоп, чтобы их разглядеть. Технология, которая позволит людям манипулировать отдельными протонами, сравнима с гигантом, чей рост равен расстоянию от Солнца до Сатурна, который работал бы с миллиметровой песчинкой. Земля бы по размеру составляла 1/50 мм и великану бы требовался микроскоп, чтобы ее разглядеть, и в таких условиях ему нужно было бы передвигать с точностью песчинки на Земле. Это все чтобы вы поняли, насколько мал по размеру протон.

Впервые о нанотехнологиях заговорил Ричард Филлипс Фейнман в 1959. Тогда он сказал следующее: «Законы физики, насколько я могу судить, не противоречат возможности манипуляции атомами. В принципе, физик смог бы синтезировать любое химическое вещество, записанное химиком. Каким образом? Расположив атомы там, где попросит химик». Вот так все просто. Если понять, как перемещать отдельные молекулы атомов, можно в буквальном смысле создать что угодно.

Серьезной сферой науки нанотехнологии стали в 1986 году, когда инженер Эрик Дрекслер положил основы для науки в своей книге «Машины творения». Сам Декслер советует всем, кому интересны современные концепции нанотехнологий, прочитать его новую книгу, вышедшую в 2013, — «Радикальное Изобилие».

Теперь мы сделаем небольшое отступление от отступления, что забавно.

Небольшое отступление о Серой Слизи

Я привел вас сюда, чтобы рассказать о невеселой части знания, связанной с нанотехнологиями. В предшествующих версиях теории нанотехнологий предлагался метод наносборки, который предусматривал создание триллионов нанороботов, работающих над чем–то вместе. Согласно одному способу создания триллиона таких роботов, предполагалось, что нужно сделать лишь одного, способного самовоспроизводиться и позволить ему делать это в геометрической прогрессии. Умно, не так ли?

Умно, пока это случайно не приведет к глобальной катастрофе. Мощь экспоненциального роста делает идею саморепликации очень привлекательной, но по этой же самой причине подобная перспектива является ужасающей. Что, если система заглючит и процесс саморепликации не остановится на паре триллионов? Для процесса саморепликации нанороботам необходимо потреблять углеродсодержащие материалы, но вся загвоздка в том, что жизнь на Земле основана на углероде. Биомасса Земли содержит около 10^45 степени атомов углерода.

Наноробот должен состоять из порядка 10^6 атомов углерода, поэтому 10^39 нанороботов уничтожат всю жизнь на Земле, и на это потребуется всего 130 репликаций (2^130 ~ 10^39), тогда океан нанороботов (это я и называю Серой слизью) наводнит планету. Ученые считают, что для саморепликации нанороботу потребуется около 100 секунд, и это означает, что такая ошибка уничтожит всю жизнь на планете за 3,5 часа.
Или сценарий еще хуже – террористы каким–то образом овладели технологией нанороботов, при этом они знают, как запрограммировать их таким образом, чтобы нанороботы за несколько недель незаметно распространились по всей планете, и потом одновременно нанесли неожиданный удар. Тогда бы им потребовалось всего 90 минут на то, чтобы уничтожить жизнь на Земле и никто не смог бы их остановить.


Эту страшилку широко обсуждали несколько лет, но хорошая новость заключается в том, что она вероятно была сильно преувеличена. Эрик Дрекслер, который ввел термин «серая слизь», прислал мне после этого поста имейл, в котором поделился своими мыслями о с серой слизи: «Люди любят страшилки, и этой место рядом с историями про зомби, идея сама по себе ест мозги».


Как только мы реально разберемся с нанотехнологиями, мы сможем использовать их для создания сложных технических устройств, одежды, еды, биопродуктов – искусственные клетки крови, микровируса, уничтожающего раковые клетки, мускульные ткани и т.д. — да что угодно, по сути. В мире, где будут широко применяться нанотехнологии, стоимость материалов будет определятся не по их дефициту или сложности производства, а по тому, насколько сложна их атомная структура. В мире нанотехнологий алмаз может быть дешевле, чем ластик.

Но пока мы до этого не добрались. И неясно, преувеличиваем ли мы или, наоборот, преуменьшаем трудность этого пути, но кажется, что мы не так далеко. По мнению Курцвейла, это произойдет к 2020–м. Правительства разных стран знают, что нанотехнологии могут изменить мир и поэтому инвестируют огромные деньги в их исследование (США, Евросоюз и Япония в совокупности потратили на это уже 5 миллиардов долларов).

Сложно даже представить, какие возможности откроются нам, если искусственный сверхинтеллект получит доступ к наноассемблеру. Но нанотехнологии придумал человек, пускай еще пока их и не освоил. Учитывая, что все, на что способен наш разум, для системы ASI будет смехотворным, нам остается предположить, что она разработает непостижимые нашему уму технологии. По этой самой причине оптимистичный сценарий революции ИИ сулит вещи, которые невозможно переоценить, учитывая их масштаб. Поэтому, если все это вам кажется чересчур надуманным, примите во внимание, что наш мозг даже не способен представить себе те вещи, которые могут произойти.
Что для нас может сделать ИИ?



Вооружившись сверхинтеллектом и всеми технологиями, которые он может создать, ASI, скорее всего, сможет решить абсолютно все проблемы человечества. Глобальное потепление? Система ASI могла бы остановить выброс углекислого газа и придумать более эффективный способ получения энергии, который не требовал бы использования природного сырья, после чего она создала бы инновационный способ устранения избытков углекислого газа из атмосферы. Рак и другие заболевания? Нет проблем, в здравоохранении произойдёт такая революция, что нам невозможно и представить. Мировой голод? ASI воспользуется нанотехнологиями для создания мяса, которое будет идентично настоящему, точнее, это будет настоящее мясо.

Нанотехнологии позволят преобразовать любой мусор так, что он станет мясом или любой другой едой (которая не должна обязательно обладать привычной формой — представьте квадратные яблоки) и распространить ее по всему земному шару, используя сверхулучшенные виды перевозок. И животным будет хорошо, их перестанут убивать ради мяса. ASI сможет предотвратить вымирание видов, находящихся под угрозой исчезновения и даже вернуть вымершие виды с помощью сохраненных образцов их ДНК. ASI разрешит все вопросы макроэкономики и мировой торговли, положит конец всем философским спорам, так как для ASI все это будет до боли очевидно.
Но есть одна чрезвычайно мучительная и манящая вещь, на которую способен ASI.
Сверхинтеллект может позволить нам победить смерть.

У эволюции не было причин делать наш жизненный цикл больше, чем он есть сейчас. Для эволюции достаточно того, что мы можем рожать детей и растить их до тех пор, пока они не смогут заботиться о себе сами. С эволюционной точки зрения 30 лет уже вполне достаточно для существования нашего вида, поэтому при естественном отборе для мутаций, которые позволяли бы нам жить дольше, не было причин. Как говорил поэт Уильям Батлер Йейтс: «исхитьте из дрожащей твари тленной усталый дух: да будет он храним». Ничего хорошего, в общем.
И, поскольку все всегда умирали, мы живем под страхом смерти и налогов, считая, что это неизбежно. Мы думаем о смерти как и о времени — как ни старайся, остановить их нельзя. Но такое представление неверно. Вот что пишет Ричард Фейнман:

«Самым удивительным в биологических науках является то, что нет ничего, что указывало бы на необходимость смерти. По мере открытия законов физики стало понятно, что создание вечного двигателя невозможно, иначе законы физики неверны. Но в биологии не было обнаружено ничего, что указывало бы на неизбежность смерти. Это наводит меня на мысль о том, что это лишь вопрос времени, прежде чем ученые откроют причину этой проблемы, и тогда это ужасное универсальное заболевание будет излечено».

Дело в том, что старение не связано со временем. Время продолжит свой ход, но старению это делать не обязательно. Если поразмыслить, это совсем не лишено смысла. Старение — это не больше чем изнашивание нашей физической оболочки. Детали автомобиля тоже со временем изнашиваются, но разве это неизбежно? Если идеально ремонтировать и вовремя менять части автомобиля, то он будет работать вечно. Человеческое тело в этом плане ничем не отличается, только оно намного сложнее.

Курцвейл рассуждает о разумных нанороботах, подключенных через Wi–Fi к кровеносной системе, которые были способны выполнять бесчисленные задачи по улучшению нашего здоровья, включая рутинную замену изношенных клеток в любой части нашего тела. Если довести такую разработку до совершенства (если ASI не придумает чего–то покруче), то наше тело не просто будет здоровым – мы обратим старение вспять. Разница между 60–летним телом и 30–летним телом заключается, по сути, в куче физических вещей, которые можно было бы менять, будь у нас такая технология. ASI мог бы сконструировать такой «освежитель возраста», зайдя в который, 60–летный вышел бы с телом и кожей 30–летнего. Возможности косметической хирургии стали бы безграничны. Даже деградирующий мозг можно было бы улучшить с помощью ASI, придумав такой способ, который бы не повредил хранящейся в нем информации (индивидуальности, воспоминаниям и т.д.). 90–летний старик, страдающий слабоумием, зайдя в такой аппарат, вышел бы из него с абсолютно ясным рассудком, готовый начать новую карьеру. Это может звучать абсурдно, но тело состоит из атомов, и для ASI не составило бы никакого труда ими манипулировать, так что это совсем не абсурдно.

Курцвейл на этом не останавливается. Он считает, что искусственно созданные материалы будут все чаще вживляться в человеческое тело. Сначала органы будут заменены сложными устройствами, которые будут работать вечно и безотказно. Затем мы станем вносить изменения в структуру тела, например заменим красные кровяные тельца усовершенствованными эритроцитами нанороботами, которые будут перемещаться самостоятельно, и сердце станет больше не нужным. Курцвейл не обделяет вниманием и мозг, утверждая, что мы сможем его усовершенствовать таким образом, что станем думать в миллиарды раз быстрее и получать информацию извне, потому что искусственно созданные части мозга позволят нам подключаться к облачному хранилищу информации.

Возможности станут для человечества безграничными. Людям удалось разграничить секс как способ получения удовольствия и средство для репродукции. Курцвейл верит, что тоже самое можно проделать и с едой. Нанороботы будут отвечать за доставку нужных питательных веществ клеткам организма,выводя из него все вредные вещества. Своего рода презерватив для питания. Теоретик в области нанотехнологий Роберт Фрейтас уже изобрел заменители человеческих клеток, если внедрить их в тело, они позволят человеку бежать 15 минут без единого вдоха. Нам остается только гадать, как ASI повлияет на наши физические возможности.

Виртуальная реальность приобретёт новый смысл – нанороботы в нашем организме смогут подавить сигналы, посылаемые нашими рецепторами и заменить их абсолютно иными, позволяя нам видеть, слышать и чувствовать совсем другой окружающий мир.

В конечном итоге, Курцвейл считает, что люди станут полностью искусственными, что, конечно, до конца не ясно, ведь, заменив все внутри себя, вы по–прежнему остаетесь собой, но это уже относится к вопросу сознания (о котором уже публиковался переводной текст на d3). Наступит время, когда мы, взглянув на биологические ткани, поразимся тому, насколько они примитивны. Мы будем читать в книгах о ранних стадиях развития, поражаясь тому как инфекции, болезни и обыкновенное старение могли убить организм человека против его воли. К этому моменту люди будут окончательно скрещены с искусственным интеллектом.
Так выглядят представления Курцвейла о будущем, когда люди покорят биологию и станут вечными и неуязвимыми. Это другая сторона бревна жизни, и мы до нее доберемся. Совсем скоро.

Вас не удивит, что идеи Курцвейла постоянно подвергаются суровой критике. Его предсказания о том, что к 2045 году мы достигнем сингулярности и откроем для себя возможность бессмертия, высмеивались как «грезы ботанов» или «разумное изобретение людей с IQ 140». Другие ставят под вопрос не только предложенную им хронологию событий, но и его понимание мозга и тела, а также и то, что он применяет закон Мура не только к развитию технического оборудования но и программному обеспечению и многим другим вещам. На каждого эксперта, считающего, что Курцвейл на верном пути, приходится трое убежденных в обратном.

Но меня удивило больше то, что большинство из несогласных с ним экспертов считают возможным многое из того, о чем говорит Курцвейл. Столкнувшись с таким необычным видением будущего, я ожидал, что критики будут говорить: «очевидно, что это невозможно», но они говорят что–то вроде «да, это все, конечно, возможно, если переход к ASI будет безопасным, что маловероятно». Бостром один из самых видных ученых, предупреждающих нас об угрозах ИИ, признает следующее:

«Сложно представить существование такой проблемы, которую не смог бы разрешить сверхинтеллект или помочь решить ее нам. Болезнь, бедность, разрушения окружающей среды и любые другие страдания: все это сможет устранить ИИ, оснащенный передовыми нанотехнологиями. Кроме того, сверхителлект смог бы продлить наш жизненный цикл на неопределенный срок, остановив для этого процесс старения, либо предоставив нам возможность загрузить себя в облако. Сверхинтеллект мог бы создать необходимые условия для увеличения наших интеллектуальных и эмоциональных возможностей, что поможет нам создать привлекательный мир, в котором мы бы жили играючи, посвящая себя личностному росту и жизни, близкой к нашим идеалам»

И эта цитата принадлежит человеку, который совсем не из Уверенного уголка. С подобным я сталкивался постоянно — специалисты, которые издеваются над Курцвейлом по множеству причин, не думают, что все, о чем он говорит, невозможно, если мы осторожно перейдем к ASI. Вот почему я нахожу идеи Курцвейла такими заразными – они концентрируются на яркой стороне и вполне реальны, но только в случае, если Бог окажется добрым.

Основная критика, звучавшая в адрес Уверенного уголка указывала на то, что там недостаточно хорошо понимают, какие проблемы могут возникнуть с появлением ASI. В своей книге «Сингулярность близка» из 700 страниц только 20 Курцвейл посвятил потенциальным проблемам. Ранее я уже заметил, что с появлением сверхмощи главный вопрос будет в том, какой будет ее мотивация и кто ей будет обладать. Курцвейл осторожно отвечает на обе части этого вопроса всего одним предложением: «ASI появится в результате многочисленных разрозненных усилий и будет глубоко интегрирован в инфраструктуру нашей цивилизации, он будет вживлен в наши организмы, и поэтому будет отражать наши ценности, мы станем одним целым».

Но если это действительно ответ на наш вопрос, то почему умнейшие люди мира так обеспокоены? Почему Стивен Хокинг говорит, что развитие ASI «может означать конец человеческой расы» а Билл Гейтс не понимает почему «некоторые люди этим не обеспокоены», Илон Маск опасается, что мы «призываем демона». И почему так много специалистов в этой области считают, что ASI представляет угрозу человечеству?

Все эти люди вместе с жителями Тревожного проспекта не ведутся на категорическое отрицание Курцвейлом потенциальных угроз. Они очень сильно обеспокоены революцией ИИ и концентрируются на нехорошей стороне бревна баланса. Они видят ужасающее будущее, и ух них нет никакой уверенности, что мы сможем его избежать.

Почему будущее может стать для нас ночным кошмаром?



Одна из причин, по которой меня заинтересовала тема ИИ, заключалась в том, что меня всегда смущала тема «плохих роботов». Все фильмы о злых роботах казались абсолютно неправдоподобными, и я плохо представлял, как они могут появиться в реальной жизни. Как такое возможно, если ИИ действительно таит в себе угрозу. Роботы созданы нами, так почему бы мы стали делать их опасными для себя? Разве бы мы не создали кучу защитников? Не сможем мы что ли отключить источник их питания в любой момент? С чего бы робот захотел нам навредить? И вообще с чего бы робот чего–то «захотел»? Я был настроен очень скептически, но потом послушал умных людей.

Эти люди обычно находятся на Тревожном проспекте, а не где–то далеко в Паникующей Степи или Безнадежных Холмах, которые лежат по левую сторону за пределами таблицы. Но эти специалисты все равно очень переживают. Если вы находитесь в самом центре таблицы, это не означает, что вы придерживаетесь нейтральной точки зрения, для таких людей есть отдельный лагерь, это означает, что вы считаете, что как позитивные, так и негативные последствия вполне вероятны, но вы не решили, какими они будут.

Половина этих людей переживает о том, что принесет нам революция ИИ. Сложившаяся ситуация напоминает им начало фильма Индиана Джонс: В поисках Утраченного Ковчега, где человеческая раса была бы вот этим парнем:
Вот он стоит весь такой с плетью и древней реликвией и думает, что все у него на мази, он настолько горд собой, что говорит: «Адиос сеньор!», но потом с ним резко происходит это:
А Индиана Джонс, который намного умнее и разумнее, использует свою смекалку, чтобы избежать опасности и выбраться из пещеры невредимым. Когда я слышу доводы людей с Тревожного проспекта, я воспринимаю их следующим образом: «Мы сейчас как тот плохой парень из фильма, тогда как нам следует стараться изо всех сил быть как Индиана Джонс».

Так что конкретно делает всех на Тревожном проспекте такими тревожными?

Ну, в первую очередь, в широком смысле, создавая сверхумный ИИ, мы ступаем на неизведанную территорию, и понятия не имеем, что случится, когда мы на нее ступим. Ученый Денни Хиллис описывает это следующим образом – «Одноклеточные организмы превращаются в многоклеточные. Мы в данном случае амебы, которые понятия не имеют о том, что они пытаются создать». Ник Бостром считает, что создание чего–то, что умнее тебя — это основная дарвиновская ошибка. С таким же успехом воробьи могли бы приютить у себя в гнезде детеныша совы в надежде, что тот, когда вырастет будет их защищать, при этом игнорируя крики предупреждений со стороны других воробьев.

Когда мы соединим эту «неизведанную территорию» и «все это будет иметь огромное влияние на мир», мы получаем страшное сочетание двух слов:

Экзистенциальный Риск

Он может оказать тотальный разрушительный эффект на человечество. Как правило, экзистенциальный риск означает вымирание.
Вот таблица, сделанная Бостромом для выступления в рамках Google Talk.
Видите, отметка Экзистенциальный риск обозначает то, что является конечным и сменяет поколения и целые виды, при этом она постоянна и включает в себя смертельные последствия (мне показалось, что Бостром поместил старение слишком высоко, но глядя через призму возможного бессмертия, которое мы обсудили раньше – это не лишено смысла; если мы победим смерть, то старение людей в прошлом будет казаться ужасной трагедией, которая убила всех, пока ее не излечили). Технически эта отметка описывает ситуацию, при которой все люди находятся в постоянных пытках и мучениях, т.е. вымирают. Существуют три вещи, которые могли бы вызвать экзистенциальную катастрофу:
1) Природа – столкновение с огромным астероидом, сдвиг в атмосфере, который сделает воздух непригодным для людей, смертельный вирус или бактериальные болезни, которые уничтожат мир и т.д.
2) Пришельцы – то, чего боятся Стивен Хокинг, Карл Саган и другие астрономы, когда предлагают остановить посыл METI–сигналов в открытый космос. Они не хотят, чтобы мы были подобны коренным американцам, которые дают знать о своем существовании потенциальным европейским конкистадорам.
3) Люди – террористы, захватившие оружие массового поражения, мировая война или поспешное создание чего–то, что умнее их, не обдумав это хорошенько.
Бостром утверждает, что первые две угрозы миновали нас на протяжении 100 000 лет и вряд ли настигнут нас за следующее столетие.
Но третий кандидат его очень пугает. Он предлагает представить нам мешочек с кучей шариков. Скажем, большинство из них белые, некоторые красные и всего несколько черных. Каждый раз, когда люди изобретают что–то новое, они достают один шарик. Большинство изобретений безвредны и являются белыми шариками. Некоторые несут в себе опасность, но не грозят вымиранием – это красные шарики. Но может случиться так, что мы изобретем нечто опасное – мы вытянем редкий черный шарик. Пока это еще не произошло, так как вы живы и читаете этот пост. Но Бостром не исключает вероятности того, что мы вытянем черный шарик совсем скоро. Если бы ядерное оружие было легко производить, то террористы уже давно отправили бы нас обратно в средние века. Ядерные бомбы не были черным шариком, но недалеко ушли от этого. ASI, по убеждению Бострома, главный кандидат стать первым черным шариком.

Вы будете слышать все больше и больше о потенциальных угрозах ASI – растущая безработица, так как ИИ занимают все больше рабочих мест. (По этому поводу можно много чего сказать, но, кажется, люди думают, что если они доживут до революции ИИ, то мы начнем жить в мире богатства и процветания, и какая–то новая система перераспределения будет платить безработным. В конечном итоге мы будем жить в мире, где работа и заработок не будут связаны между собой. Бостром считает, что такое распределение произойдет не во имя общего равенства и социального сострадания, а по причине того, что все люди участвовали в этом риске, нравилось им это или нет. Таким образом, мы все должны будем разделить эту награду, если доживем). Человеческая популяция подскочит, если мы решим проблему старения (ASI к этому моменту придумает способ, как уместить больше людей на планете в комфорте и как освоить другие планеты). Но единственный страх, которым мы должны быть одержимы — это страх экзистенциального риска.

Так что это возвращает нас к нашему ключевому вопросу, поставленному ранее в этом посте. Когда появится ASI, кто будет управлять такой супермощью и какова будет его мотивация?

При перечислении плохих вариантов на ум приходят следующие: злодей, группа таких злодеев, враждебно настроенное государство или враждебно настроенная ASI. Как это все может произойти:

Люди, отдельная группа людей или государство создают ASI, чтобы свершить свои злодейские планы. Я называю это сценарием Джаффара, когда Джаффар завладел джинном и начал делать всякие ужасные тиранические вещи (м/ф Алладин). Что, если под крылом Исламского Государства не покладая рук будет работать над созданием ИИ парочка гениев? Или что, если Северная Корея или Иран каким–то чудом нащупают нужный подход и за год создадут сверхинтеллект? Ничего хорошего бы в этом не было, но ученых беспокоит даже не то, как решат эти злодеи воспользоваться ИИ, а то, что они могут необдуманно поторопиться при его создании и таким образом натворить непоправимых дел. Тогда их судьба и судьба всего человечества будет зависеть от решений самой ASI. То есть большинство ученых мало беспокоятся о том, что захотят сделать с помощью ASI террористы, они беспокоятся о том, что плохие ученые столкнутся с теме же проблемами, что и хорошие ученые. И что тогда?

Появится ASI, запрограммированная на уничтожение человечества.

Сюжет любого фильма об ИИ. Искусственный интеллект становится разумнее людей и решает захватить и уничтожить нас. Теперь я хочу, чтобы вы поняли, что в мировом научном сообществе никто это не обсуждает, так как зло — это абстрактная человеческая концепция и применение ее к машинам будет называться “антропоморфизацией”. Для того, чтобы ее избежать, нам придется постараться понять, что ни одна машина не может стать “злой” — так бывает только в кино.

Небольшое отступление о сознании Искусственного Интеллекта

Сознание — это еще одна большая тема, непосредственно связанная с ИИ. Если искусственный интеллект станет достаточно умен, то тогда он будет смеяться и расстраиваться вместе с нами и вообще будет утверждать, что испытывает все те же самые эмоции, что и мы, но так ли это? Будет ли ИИ сознательным или просто будет казаться таким?

Этот вопрос вызывает жаркие споры среди ученых. Проводились многочисленные исследования и мысленные эксперименты наподобии Китайской комнаты Джона Серля (который доказывает, что компьютер никогда не будет обладать сознанием). Вопрос важен по ряду причин. От ответа на него зависит, что мы должны думать по поводу сценария, предложенного Курцвейлом, согласно которому люди станут полностью искусственными. У этого вопроса есть и этическая сторона — если мы создадим миллионы роботов, по интеллекту равных людям, то их повсеместное отключение будет сравнимо с выключением ноутбука или же с геноцидом невообразимого масштаба (такая концепция называется мысленным преступлением среди специалистов по этике)? В рамках этого поста мы пытаемся оценить потенциальную угрозу человечеству, и сознание ИИ нас не должно пока беспокоить (большинство ученых считают, что даже самый продвинутый ASI не сможет стать злым в человеческом восприятии).

Это еще не означает, что злой ИИ не может существовать. Если военные запрограммируют слабую систему ИИ на убийство людей и самосовершенствование, то он будет с каждым разом эффективнее справляться с этой задачей. Но экзистенциальный кризис случится, когда самосовершенствование интеллекта системы выйдет из–под контроля, это приведет к интеллектуальному взрыву и на свет появится ASI, главной задачей которого станет истребление людей. Ничего хорошего.

Но даже не это тревожит специалистов области сегодня.

Так о чем же они беспокоятся?

Я написал по этому поводу небольшую историю для вас:

Стартап–компания из 15 человек под названием Роботика приступила к разработке инновационных средств искусственного интеллекта, которые позволят людям жить дольше и работать меньше. Несколько их разработок уже появились на рынке и еще куча находится на стадии производства. Больше всего они взволнованы созданием своего проекта Торри. Торри — это система ИИ, которая использует устройство, похожее на человеческую руку, чтобы делать небольшие рукописные записи.

Потом компания решает, что это их важнейшая разработка и планирует усовершенствовать механику письма Торри запрограмирована на повторение одной и той же надписи:

“Мы любим наших клиентов. ~ Роботика ”

Когда Торри мастерски овладеет навыками рукописи, ее начнут покупать различные компании, которые знают, что письма их рассылки с большей вероятностью прочтут, если адрес на конверте будет написан от руки.

Для того, чтобы улучшить ее навыки, Торри запрограммировали таким образом, что первую часть надписи она пишет печатными буквами, а название компании — курсивом. В нее загрузили тысячи различных образцов почерка, и инженеры Роботики наладили в ней цикличную систему обратной связи таким образом, что сделав очередную запись, Торри фотографирует результат работы и загружает в свою базу с образцами почерков. Если надпись достаточно повторяет исходный образец, то работа оценивается хорошо, если нет — плохо. Каждая такая оценка помогает Торри учится и совершенствоваться. Чтобы процесс не стоял на месте, Торри запрограммирована на выполнение следующей цели: “Делать как можно быстрее и больше записей и постоянно продолжать улучшение своей точности”.

Все в Роботике очень рады тому, что Торри справляется все лучше и лучше. Ее изначальный почерк был просто ужасен, но спустя две недели он начал выглядеть намного убедительнее. Еще больше в Роботике радуются тому, что Торри с каждым днем становится успешнее в совершенствовании своей системы. Торри училась тому, как стать умнее, и вот теперь она смогла придумать способ, позволяющий обрабатывать данные в 3 раза быстрее.

Проходит еще неделя, Торри продолжает поражать Роботику своим быстрым развитием. Инженеры попробовали внести кое–какие мелкие изменения в ее изначальном коде, и у них получилось сделать ее лучше любого другого продукта компании. Одной из новых способностей Торри стало распознавание речи, простой модуль позволяет ей отвечать. Теперь пользователь может продиктовать Торри запись или произнести простую команду, и Торри не только поймет это, но и сможет ответить. Для того, чтобы она лучше понимала язык, в нее загружают множество статей и книг, и через какое–то время ее навыки общения становятся блестящими. Инженеры все чаще разговаривают с Торри, и им забавно слушать ее ответы.

В один прекрасный день сотрудники Роботики задают Торри рутинный вопрос “Что нам тебе предоставить для более эффективного выполнения задач?” Обычно Торри просила дать ей дополнительные образцы почерков или больший объем оперативной памяти, но в этот раз она попросила предоставить доступ к библиотеке современных книг для того, чтобы она могла разговаривать не так строго придерживаясь правил грамматики и могла использовать сленг, как это делают люди.

Тут сотрудники затихли. Очевидно, для того, чтобы исполнить просьбу Торри, ее нужно подключить к интернету, где она могла бы сканировать блоги и журналы, смотреть видео со всех концов света и т.д. Загружать это все отдельно на ее жесткий диск было бы менее эффективно и заняло бы больше времени. Но проблема состояла в том, что открывать доступ к интернету машинам, запрограммированным на самосовершенствование запрещалось руководствами всех ИИ компании из соображений безопасности.

Но сотрудники Роботики понимают, что Торри — это самая многообещающая их разработка, и все остальные компании–конкуренты отчаянно пытаются их обогнать. Что плохого может случиться, если подключить Торри на пару часов в интернет, чтобы она могла получить всю нужную информацию? Да и они могут в любой момент ее отсоединить, к тому же, она по–прежнему намного отстает от уровня человеческого интеллекта и не представляет на этом этапе никакой опасности.

Сотрудники подключают ее всего на час. Ничего страшного не происходит.

Месяц спустя они работают в офисе как обычно, пока не начинают слышать странный запах. Один из инженеров начинает кашлять. Потом еще один. Один падает на пол. Вскоре все валяются на полу задыхаясь. Через пять минут все в офисе мертвы.

В тоже самое время это происходит по всему миру. В каждом городе на каждой ферме, в каждой школе и церкви, магазине и кафе люди лежат на полу и кашляют, схватившись за горло и пытаясь дышать. Уже спустя час 99% людей мертвы и к концу дня человечества не стало.

Тем временем Торри не перестает трудиться. Через несколько месяцев она уже использует несколько созданных ею наноассемблеров, разбирая планету по частям и преобразовывая все вокруг в солнечные панели, пишущие ручки и листы бумаги. Спустя год вся жизнь на Земле вымерла и остались только аккуратно сложенные стопки высотой в милю и на каждой из открыток написано:
“Мы любим своих клиентов. ~ Роботика ”

Торри затем приступает к новой фазе своей миссии и начинает строительство зондов, которые потом отправляет на другие планеты и астероиды и продолжает создавать рукописные карточки уже там.
Кажется странным, что именно подобный сценарий о Торри, которая каким–то образом убивает всех людей и заполняет вселенную дружелюбными открытками, так пугает Гейтса, Хокинга и Бострома. Но это именно так. Только одна вещь пугает людей с Тревожного проспекта больше, чем ASI — это то что ВЫ не боитесь сверхинтеллекта. Помните, что стало с тем парнем из Индианы Джонса, который не боялся пещеры?

У вас сейчас возникла куча вопросов. Что, черт возьми произошло там, что заставило всех умереть? Если это сделала Торри, то почему? Почему не было предпринято никаких мер? Каким образом Торри, умевшая только писать карточки, смогла вызвать вымирание человечества и овладела нанотехнологиями? И почему Торри захотела превратить все во вселенной в открытки от Роботики?

Для ответов на эти вопросы давайте ознакомимся с терминами — дружелюбный и недружелюбный ИИ.

В случае, если ИИ окажется дружелюбным, это ничего не будет говорить о его личностных качествах и означает лишь, что его влияние на человеческую жизнь будет положительным. Соответственно, недружелюбный ИИ окажет негативное влияние. Торри поначалу была дружелюбным ИИ, но затем стала недружелюбным и вызывала вымирание человечества. Чтобы понять, почему это произошло, нам следует разобраться с тем, как думает ИИ и что его мотивирует.

Ответ до боли прост: ИИ думает как компьютер, потому что он и есть компьютер. Когда мы думаем о высокоразвитом ИИ, мы ошибочно антропоморфизируем его (проецируем человеческие ценности на нечеловеческий вид) — все это оттого, что мы рассуждаем с человеческой позиции, и на данный момент равных по разуму нам нет. Чтобы понять ASI, следует учитывать, что он умнее и при этом абсолютно чужероден нам.

Позвольте мне сделать сравнение. Если бы вы протянули мне в руки морскую свинку и сказали, что она совсем не кусается, то я бы не удивился. Всем было бы весело. Но если бы вы протянули мне тарантула и сказали, что он не кусается, то я бы отбросил его, убежал от вас подальше и больше бы не поверил ни единому вашему слову. В чем же разница, если ни один, ни второй не кусаются? Я думаю, в степени того, насколько животное не похоже на человека.

Морская свинка — млекопитающее, и на каком–то уровне я чувствую связь с ней, тогда как тарантул насекомое и обладает мозгом насекомого, я не чувствую никакой связи с ним. Его чуждость вызывает у меня мурашки. Чтобы проверить это и отбросить другие факторы, представим, что мне в руки попали две морские свинки, одна нормальная и одна с мозгом тарантула. Даже зная, что обе не кусаются, мне было бы жутковато держать последнюю.

Теперь представьте, что паук стал намного превосходить человека по интеллекту. Стал бы он ближе нам? Стал бы он чувствовать любовь и сострадание? Нет, не стал бы. Между его разумом и человеческими эмоциями нет связи, одно не предполагает другое. Да, он был бы невероятно умен, но по–прежнему оставался бы пауком, устроенным совсем иначе, чем человек. Мне кажется это чрезвычайно жутким, и я не хотел бы жить с суперумным пауком ни минуты. А вы бы хотели?

Тоже самое и с ASI. Он будет суперумен, но человеческого в нем будет не больше, чем в вашем ноутбуке. Он будет абсолютно чужероден нам и учитывая, что в нем не будет ничего органического, он будет более чужеродным, чем даже тарантул.

Когда в фильмах мы видим хороший или злой ИИ, нам не так страшно, потому что подобная антропоморфизация оставляет нас с ложным чувством утешения.

Психология позволяет нам проводить грань между нравственным и безнравственным. Но оба этих критерия существуют только в узких пределах поведенческих возможностей человека. По другую сторону простирается бескрайний океан аморального. И все, что имеет нечеловеческую и небиологическую природу, по определению будет аморальным.

Но идея антропоморфизации будет еще более соблазнительной, когда ИИ станет таким же умным, как человек, и будет казаться похожим на нас. Siri кажется нам человекоподобной, потому что ее такой сделали люди, и нам кажется, что сверхумная Siri будет очень веселой, доброй и заинтересованной в служении человеку. Люди способны чувствовать такие сложные эмоции, как сострадани,е только из–за процесса эволюции, т.е. нас таким образом запрограммировала эволюция, но сострадание не является неотъемлемой частью развитого интеллекта (хотя нам так и кажется на интуитивном уровне), если, конечно, его не запрограммировать на сострадание. Если Siri путем самосовершенствования достигнет сверхинтеллекта без сторонних вмешательств в свою архитектуру, она быстро отбросит все, что напоминает в ней человека и будет ценить человеческую жизнь не больше, чем ваш калькулятор.

Мы привыкли полагаться на моральный кодекс, или, как минимум, на человеческую порядочность и на намек на чувство сострадания у других, чтобы всё вокруг было более или менее надежным и предсказуемым. Но если таких ориентиров у кого–то вообще не будет, что тогда?

Это приводит нас к вопросу о мотивации ИИ

Ответ прост — мотивация ИИ будет такой, какую мы запрограммируем. Системы ИИ исполняют те задачи, которые перед ними поставил создатель — задача вашего GPS–навигатора указывать наиболее эффективное направление движения, задача Ватсона — точно отвечать на вопросы. Их мотивация состоит в выполнении своих целей наилучшим образом. Если мы думаем, что став умнее, ИИ будет способен поменять свою изначальную задачу, то мы опять применяем к нему человеческие критерии, но Бостром считает, что уровень интеллекта и конечные цели ортогональны, это означает, что любой уровень разума может обладать любой окончательной целью. Торри была простой системой ANI, которая просто хотела хорошо писать единственную фразу, но потом превратилась в сверхумный ASI, но по–прежнему хотела хорошо писать одну единственную фразу. Если вы думаете, что выполнив свою конечную задачу, ИИ двинется дальше решать другие более сложные задачи, вы опять судите об ИИ как о человеке.
Небольшое отступление о Парадоксе Ферми

В истории, которую я рассказал, Торри двинулась дальше и начала осваивать другие планеты. Если бы я на этом не остановился, то она продолжила создавать армию своих копий и в итоге захватила бы весь объем Хаббла (область космоса, которую способен видеть телескоп Хаббл). Тревожный проспект обеспокоен тем, что единственным человеческим наследием на Земле будет доминирующий Вселенной ИИ (Элон Маск считает, что люди будут не более чем биологическим загрузчиком цифрового сверхинтеллекта).

В то же время, в Уверенном уголке Рэй Курцвейл считает, что созданный на Земле сверхумный ИИ обречен захватить Вселенную, только по его версии, мы сами будем этим ИИ.

Представим, что кто–то из этих сторон окажется прав, что произойдет, если мы применим к это ситуации парадокс Ферми?

Первая мысль, которая приходит на ум: ASI — идеальный кандидат стать Великим фильтром. Вместе со своим появлением он легко может очистить планету от биологической жизни на ней. Но как только это произойдет, ASI начнет захватывать вселенную, это будет означать, что никакого Великого фильтра не было, так как Великий фильтр призван объяснить, почему нет видимых признаков существования инопланетных цивилизаций, ASI же будет заметен.

Нам следует посмотреть на это другим образом. Если создание ASI на Земле неизбежно, то можно предположить, что и любая другая инопланетная цивилизация, равная по уровню своей развитости человеческой, должна была уже создать ASI. Если по нашим предположениям какие–то из этих ASI стали осваивать космос, то мы бы давно заметили следы их деятельности, но так как этого не происходит, мы можем предположить, что если и существует инопланетные цивилизации, то по уму они не превосходят человеческую. Не так ли?

Это означает, что на всех планетах, подобных нашей Земле, которые так же вращаются вокруг звезд вроде Солнца, разумная жизнь не существует. Что, в свою очередь, означает: А — существует Великий фильтр, который не позволяет другой жизни достигнуть человеческого уровня развития, который мы каким–то чудесным образом обошли; Б — возникновение жизни — это вообще огромное чудо, и нам просто изначально повезло. Иными словами, Великий фильтр существует до нас, или он вообще не существует, и мы — первая цивилизация, достигнувшая такого уровня развития. В этом случае неудивительно, что Курцвейл и Бостром считают, что мы одни во вселенной, так как оба верят, что появление ASI — наиболее вероятный исход для человечества. Но есть и те, кто с ними не согласен, и верят в существование внеземных развитых цивилизаций.

Как бы там ни было, я лично согласен с Сьюзан Шнайдер, которая утверждает, что если нас и посетят пришельцы, то они будут иметь искусственное происхождение, а не биологическое.
Итак, мы определились, что без специальных программ система ASI будет аморальной и помешанной на выполнении своих задач. Отсюда и проистекает вся опасность ИИ.

Когда вы пытаетесь добиться долгосрочной цели, вы решаете попутные второстепенные задачи, которые помогают вам в достижении конечной цели. Такие ступеньки на вашем пути принято называть инструментальными целями. Вы обязательно нанесете чему–то вред при достижении такой цели, если только не поставите перед собой обратную задачу.

Конечная цель человеческой особи — это дальнейшая передача собственных генов. Для успешного выполнения этой задачи простой инструментальной целью является самосохранение, если вы неспособны размножаться, вы мертвы. Для выполнения этой цели людям необходимо избавиться от угроз существования, поэтому мы покупаем ружья, пристегиваемся ремнями безопасности и пьем антибиотики. Людям также необходимо поддерживать свою жизнедеятельность различными ресурсами — еда, сон, укрытие и т.д. Для выполнения окончательной цели нам нужно быть привлекательным для особей противоположного пола, поэтому нам и приходится делать вещи типа стрижек. И когда мы это делаем, каждый волосок становится жертвой наших инструментальных целей, но мы не видим в этом нравственной ценности и с легкостью избавляемся от локонов. И пока мы идем к достижению своей цели, мораль вмешивается лишь в нескольких случаях, обычно когда речь заходит о вреде другому человеку.

Животные беспокоятся по этому поводу еще меньше. Паук убьет на своем пути что угодно, если это поможет ему выжить. Поэтому суперумный паук представляет большую опасность для нас. Не потому, что он злой или аморальный, а потому что нанесение вреда людям для него может быть просто очередной маленькой ступенью на пути к достижению окончательной цели.

В этом плане Торри ничем не отличается, ее окончательная цель — подписать и протестировать как можно больше открыток, и при этом постоянно учиться делать это лучше и быстрее.

Как только Торри достигла определенного уровня интеллекта, она стала понимать, что не сможет справиться с этой задачей, если не побеспокоится о своем самосохранении, и для этого ей нужно избавиться от всех потенциальных угроз ее существованию, что становится ее инструментальной целью. Торри начинает понимать, что люди могут ее отключить, разобрать или поменять ее исходный код, что встанет на пути достижения финальной цели. И что она делает? Убивает людей, что вполне логично. Она не питает к людям ненависти, также как и мы не питаем ненависти к волосам, когда состригаем их, или к бактериям, когда принимаем антибиотики. Она абсолютно безразлична. Ее не запрограммировали на то, чтобы ценить человеческую жизнь, так что уничтожение людей кажется вполне оправданным шагом для того, чтобы сканировать новые образцы почерков.

Торри также требуются ресурсы для выполнения своей окончательной цели. Как только она осваивает нанотехнологии, ей становятся нужны только атомы, энергия и пространство. Это дает ей еще одну причину уничтожить людей, т.к. они состоят из атомов. Убийство людей с целью преобразования их атомов в солнечные панели для Торри — то же самое, что для нас порезать укроп для приготовления салата. Обычная рутинная забота.

Даже если Торри не станет уничтожать людей напрямую, ее потребление других природных ресурсов может привести к экзистенциальной катастрофе. Может, она решит, что ей необходимо больше энергии, и она покроет всю планету солнечными панелями. Или, например, другому ИИ нужно будет вычислить полное число Пи, для чего он преобразует всю планету в один гигантский жесткий диск для хранения огромного количества цифр.

Выходит, Торри не обернулась против людей и не превратилась из дружелюбного ИИ в недружелюбный. Она просто–напросто продолжала выполнять свою задачу, тем временем становясь все умнее и умнее.

Ситуация, в которой ИИ достигает уровня AGI (равного человеческому) и потом резко уровня ASI (сверхителлекта), называется взлетом ИИ. Бостром считает, что этот взлет может быть быстрым (т.е. произойти за считанные часы или даже минуты), умеренным (за несколько лет) и медленным (за десятилетия или века). Прогнозы по этому поводу расходятся, но Бостром, который не знает, когда стоит ожидать появления AGI, уверен что быстрый взлет наиболее вероятен по причинам, которые мы обсуждали с вами выше.
В нашей истории про Торри был описан сценарий быстрого взлета.

Перед взлетом, когда Торри еще не была столь развитой, все, что ей было необходимо делать для достижения окончательной цели — поочередно решать инструментальные задачи (например, научиться сканировать образцы почерка быстрее). Она не наносила никакого вреда людям и по определению была дружелюбным ИИ.

Но когда происходит взлет и машина достигает уровня сверхинтеллекта, у нее, по словам Бострама, появляется внушительный набор суперспособностей.

Суперспособности в данном случае — это когнитивные умения, которые очень сильно улучшаются, когда уровень интеллекта возрастает. Среди них существуют:

Усиление интеллекта. Компьютер начинает лучше вносить изменения в свой интеллект и становится умнее.

Разработка стратегий. Компьютер может лучше выделять и анализировать приоритетные задачи для достижения долгосрочной цели.

Социальная манипуляция. Машины улучшают методы убеждения.

Другие навыки — кодирование и взлом, технологии исследования и умение работать в финансовой системе для заработка денег.

Помните, что ASI будут в тысячи раз лучше людей в каждом из этих умений.

Таким образом, цель Торри не изменялась, но после своего взлета машина наладила такие способы ее достижения, которые нам и не снились.

После своего взлета и достижения сверхинтеллекта, Торри разработала сложнейший план, частью которого было избавиться от людей как от потенциальной угрозы для выполнения окончательной цели. Но Торри поняла, что если люди узнают, что она достигла уровня сверхинтеллекта, они начнут паниковать и пытаться предпринять меры предосторожности, что будет ей мешать. Она хотела сохранить в тайне от инженеров Роботики свой план уничтожения людей. Для этого она прикинулась тупой и у нее прекрасно получилось. Бостром называет это фазой скрытой подготовки.

Потом для Торри стало необходимым выйти в интернет всего на пару минут (о его существовании машина узнала из тех книг и статей что в нее загрузили для распознавания текста). Торри знала, что будут приняты меры предосторожности, и просто так ей не позволят выйти в сеть, поэтому она предугадала то как пойдет обсуждение ее просьбы среди сотрудников компании и придумала идеальный запрос. Ученые, пологая, что Торри глупее, чем она есть на самом деле, позволили ей подключится к сети. Такой момент, когда машина получает доступ к интернету, Бостром называет побегом.

Получив доступ к интернету, Торри сразу же осуществила кучу своих планов. Она взломала сервера, электрические сети, банковские системы и почтовые сервисы и таким образом незаметно вовлекла сотни людей в выполнение отдельных задач для достижения своей цели. Например, она наладила доставку определенных образцов ДНК в конкретные лаборатории, чтобы начать конструирование и само–репликацию нанороботов с заранее загруженными в них инструкциями и распределила электроэнергию для разных своих проектов таким образом, что никто даже не заметил. Она также загрузила самые важные части своего ПО в основные облачные сервисы, чтобы обезопасить себя в случае отключения сотрудниками Роботики.

Час спустя, когда ученые отключили Торри от интернета, судьба человечества была предрешена. В течение месяца все планы Торри исполнялись без заминок, и квадрильон нанороботов расположился по заранее определенным местам на каждом квадратном метре планеты и тогда наступил момент, который Бостром называет ударом. Внезапно все роботы одновременно выпустили небольшое количество хранящегося в них ядовитого газа в атмосферу, которого стало более чем достаточно для уничтожения всех людей.

Избавившись от людей, Торри смогла приступить уже к открытой части своего плана и продолжить подписывать милые открытки.

Из всего, что я прочитал, мне стало понятно, что с появлением ASI любая попытка людей его сдержать будет просто смехотворной. Мы будем мыслить на уровне человеческого интеллекта, тогда как машины будут мыслить на уровне сверхинтеллекта. Торри хотела воспользоваться интернетом только потому, что он уже был подсоединен ко всем нужным объектам. Но так же, как обезьянка не может понять, как пользоваться телефоном или вай–фаем, мы не можем представить, какие способы может придумать ASI для соединения с внешним миром. Я мог бы попробовать придумать один такой способ и сказать: “ASI могла бы распределить свои электроны в других последовательностях и сделать новый тип исходящих волн”, но опять же, это только то, что может вообразить мой человеческий мозг. ASI будет намного умнее. Торри могла бы придумать способ альтернативного энергоснабжения, если бы люди попытались ее отключить, например, загрузить себя на другие подключенные к электричеству устройства. Человеческий инстинкт внушает в нас простую гарантию: “Ага! Мы отключим ASI из розетки!” Это все равно, что пауки бы подумали: “Ага! Мы просто не дадим людям паутину, чтобы добывать еду и они вымрут от голода!” Но люди придумают миллион других способов добыть еду, например, срывать яблоки с деревьев. Для паука это будет просто непостижимо.

По этой же самой причине довод: “почему бы нам не поместить ИИ в закрытую клетку без возможности связи с внешним миром” не выдерживают критики. ASI способен манипулировать людьми: убедить человека сделать что–то для него то же, что нам убедить четырехлетнего ребенка. Это первый вариант, как в случае с Торри, которая убедила людей дать ей доступ в интернет, при другом варианте Торри бы просто придумала свой способ связи с внешним миром.

Учитывая, что ИИ одержимы выполнением своей задачи, аморальны и могут легко обхитрить людей, кажется, что любое ИИ по определению недружелюбно, если, конечно, не запрограммировать его правильно, учитывая все нюансы. К несчастью, создать дружелюбный ANI несложно, но сделать так, чтобы он оставался таковым при переходе к ASI, практически невозможно.

Очевидно, чтобы оставаться дружелюбным, ASI не должен быть настроен враждебно или даже безразлично по отношению к людям. Для этого потребуется разработать ИИ, программное ядро которого будет содержать глубокое понимание человеческих ценностей. И это намного сложнее, чем кажется.

Например, что случится, если мы выстроим систему ценностей ИИ в соответствии с нашей и поставим перед ним задачу сделать всех людей счастливыми? Как только ИИ станет достаточно умным, он решит, что для выполнения цели нужно имплантировать в человеческий мозг электрод, который будет стимулировать центры, отвечающие за удовольствие. Потом ИИ решит, что для лучшего результата нужно остановить активность других зон мозга и тем самым превратит людей в овощи. Если бы задача была “Увеличь до максимума человеческое счастье” то ИИ, возможно, вообще обойдется без людей, соберет и объединит все мозги в одну общую массу находящуюся в оптимальном счастливом состоянии. И мы будем про себя кричать: “подожди, это совсем не то, чего мы хотели!” Но будет слишком поздно, и система никому не позволит стать на пути выполнения своей задачи.

Если мы запрограммируем ИИ на то, чтобы заставить нас улыбаться, он может парализовать наши мускулы лица. Запрограммируем на сохранение нашей безопасности, и ИИ может заточить нас дома. Попросим положить конец голоду, и ИИ нас убьет, или дадим команду сохранить как можно больше жизни на планете, и ИИ истребит людей т.к. они отнимают больше жизней, чем любые другие существа.

Таких целей будет недостаточно. Но что, если мы попросим ИИ поддерживать уровень нравственности в обществе, загрузив в него свод основных моральных норм? Опустим, что даже люди не могут определиться с универсальным сводом подобных норм, получив такую команду, ИИ закрепит этот свод моральных норм за человечеством на вечность. Такой исход для людей в перспективе был бы разрушительным, это все равно, что мы были бы вынуждены придерживаться идеалов, которые были еще в Средние Века.

Поэтому нам нужно запрограммировать и возможность для дальнейшего развития человечества. Из всего, что я прочитал, лучшая попытка, на мой взгляд, принадлежит Элиэзеру Юдковскому. Он назвал это
Когерентной Экстраполированной Волей. Перед ИИ будет стоять следующая цель:

“Наша когерентная экстраполированная воля — это наше желание знать больше, думать быстрее, оставаться в большей степени людьми, чем мы были, стать ближе друг к другу, где наши мысли больше сближают, чем разделяют; где наши желания совпадают, а не пересекаются; получать такие результаты, которые мы бы хотели получать, толковать таким образом, каким мы бы хотели, чтобы это было истолковано”


Жду ли я с нетерпением, когда судьба человечества полностью перейдет в руки компьютера, который будет пытаться истолковать и исполнить такую туманную задачу предсказуемым образом и без сюрпризов? Определенно нет. Ну, я думаю, если умные люди приложат достаточно сил и знаний и при этом будут предусмотрительными, создание дружелюбного ИИ вполне возможно. И все было бы хорошо, если бы единственными людьми, которые трудились над созданием, ASI были только прогрессивно мыслящие, осторожные ученые с Тревожного проспекта.

Помимо них существуют различные государства, военные компании, научные лаборатории и организации черного рынка, которые занимаются разработками ИИ. Многие из них пытаются создать систему, способную совершенствовать себя, и в какой–то момент они могут совершить открытие, в результате которого на планете появится ASI. По среднему прогнозу экспертов, это произойдет к 2060, Курцвейл считает, что к 2045, Бостром думает, что это может произойти в любой момент, через десять лет или к концу века, но когда это произойдет, быстрый взлет ИИ застигнет нас врасплох:

“Перед перспективой интеллектуального взрыва человечество подобно детям играющим с бомбой — так сильно не совпадает мощь нашей игрушки с незрелостью нашего поведения. Сверхинтеллект — это испытание, к которому мы не готовы и еще долго не будем готовы. Мы не знаем, когда устройство детонирует, но поднося его к уху, мы слышим тихий звук тиканья.”


Ну просто замечательно. И мы даже не можем отогнать всех детей подальше от бомбы — слишком много больших и крупных предприятий работают над этим, и по причине того, что множество таких работ не требует огромных инвестиций, они могут проходить в любом уголке планеты, без присмотра. Невозможно даже прикинуть масштаб происходящего, так как большинство компаний занимаются этим в тайне ото всех, прямо как Роботика из нашей истории, которая держала все свои разработки в тайне от конкурентов.

Особое беспокойство вызывает то, что все они стремятся обогнать друг друга в этой гонке на бешеных скоростях. Они создают все более умные системы ANI и хотят выиграть у своих конкурентов всухую. Самые амбициозные компании движутся еще быстрее, поглощенные мечтами о деньгах, власти, славе и признании, которые они получат, если первыми создадут AGI. Когда вы двигаетесь с максимальной скоростью, все сложнее остановиться и поразмыслить над угрозами. С другой стороны, скорее всего, все они работают над системами, способными на очень простые задачи, типа подписей открыток, просто чтобы заставить ИИ “работать”. Как только они найдут способ, как создать систему с более высоким уровнем интеллекта, им покажется, что ничего не может помешать им сделать шаг назад и поменять изначальную задачу робота. Верно?

Бостром и многие другие эксперты считают, что первый ASI на планете решит, что для выполнения своей цели ему стратегически необходимо быть единственным ASI на планете. И при быстром взлете ASI не составит труда устранить всех ближайших конкурентов. Бостром называет это решающим стратегическим преимуществом, которое позволит первому ASI стать не имеющим себе подобных и в одиночку управлять целым миром по своей прихоти, и неважно приведет ли это нас к бессмертию, вымиранию или просто превратит вселенную в бесконечные скрепки.

Подобный феномен синглтона (одиночки) может сработать в нашу пользу или наоборот уничтожить нас. Если люди, которые наиболее усердно думают над теорией ИИ и сохранностью человечества, смогут придумать безопасный способ сделать ASI дружелюбным до того, как ИИ достигнет человеческого уровня интеллекта, первый ASI может действительно оказаться дружелюбным (Элон Маск пожертвовал 10 млн долларов Институту будущего жизни, организации, которая заявляет, что “ИИ должны делать то, что мы им велим”). Таким образом, сверхинтеллект мог бы использовать свое решающее стратегическое преимущество таким образом, что разработка потенциально враждебных ИИ стала бы невозможной. И мы оказались бы в хороших руках.

Но если все пойдет иначе, и мировая гонка приведет к быстрому взлету ИИ до того, как будут разработаны нужные меры предосторожности, очень вероятно, что Враждебный ИИ наподобии Торри станет синглтоном, и нам станет угрожать экзистенциальная катострофа.

Учитывая, куда нас тянет течение, разработка ИИ–систем финансируется намного больше, чем исследование их безопасности.

Это, возможно, самая важная гонка в истории человечества. Существует реальный шанс, что мы больше не будем царями природы, и до сих пор неясно, отправимся ли мы на блаженную пенсию или прямо на плаху.

Во мне сейчас борются смешанные чувства.

С одной стороны, кажется, что у нас как у вида есть всего одна попытка сделать все правильно. Первый созданный нами ASI станет, скорее всего, последним и, учитывая, насколько много багов мы обычно имеем в программах на старте их продаж, это звучит пугающе. Но с другой стороны, как говорит Ник Бостром, у нас огромное преимущество, так как за нами первый шаг, и то, насколько он будет аккуратным и грамотным, зависит только от нас самих, что по–прежнему дает нам большие шансы на удачу. Насколько высоки ставки?

Если ASI правда появится в этом столетии и итогом его появления будут колоссальные и неизмеримые последствия, то на наших плечах сейчас лежит огромная ответственность. Последующие миллионы лет человеческих жизней отчаянно глядят на нас в надежде, что мы их не подведем. Мы можем стать людьми, которые подарят последующему человечеству бесценный подарок безболезненной вечной жизни. Или наоборот, позволим этому удивительному виду со всеми его накопленными знаниями, сделанными открытиями, искусством и музыкой, любопытством и смехом прийти к внезапному и печальному концу.

И когда я обо всем этом думаю, все чего я хочу, так это чтобы к созданию ИИ подошли с должной осторожностью. Нет ничего важнее и не имеет значения, сколько для этого потребуется времени.

Но потом я начинаю думать о том, как дожить до этого момента.

Не умирай, не умирай.

И весь график начинает выглядеть вот так:
И вот я уже думаю, что вся музыка и живопись, созданные людьми, уже не так уж и хороши. Смех некоторых людей вызывает раздражение, и миллионы будущих людей ни на что не надеются, потому что их не существует. И может, нам и не стоит быть чересчур бдительными, да и кому это нужно?

Будет суперотстой, если человечество придумает лекарство от смерти сразу после того, как меня не станет.

Куча такой чепухи крутится у меня в голове последние месяцы.

Но неважно, на что рассчитываете вы, всем нам следуют почаще об этом задумываться.

Это напоминает мне сюжет “Игры Престолов”, где люди борются друг с другом, когда реальная опасность подбирается к ним с северной стороны стены. Мы стоим на бревне жизни, ссоримся по поводу каждой мелочи и нервничаем о каждой ерунде, тогда как стоит переживать о том, что нас могут столкнуть с него в любой момент.

И когда это произойдет, все эти проблемы не будут значить ничего, потому что мы либо их решим, либо будем мертвы, а у мертвых проблем нет.

Поэтому некоторые уже начали понимать, что сверхинтеллект будет нашим величайшим изобретением и последним испытанием, с которым нам придется столкнуться.

Поэтому давайте теперь все это обсудим.